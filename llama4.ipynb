{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e66bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4fe39",
   "metadata": {},
   "source": [
    "# Loading Dataset\n",
    "\n",
    "The dataset can be found at https://huggingface.co/datasets/code-search-net/code_search_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c363fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('code-search-net/code_search_net')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67f1a8",
   "metadata": {},
   "source": [
    "Here are the columns in the dataset. We will be using `func_documentation_string` for documentation and `func_code_string` for code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fdfdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8d9ab",
   "metadata": {},
   "source": [
    "Getting a random sample from the test split to test our baseline model. We will increase the size once we finalize the experimental plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae0f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = random.choices(dataset['test'], k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026741f",
   "metadata": {},
   "source": [
    "# Testing the Alternative model\n",
    "\n",
    "Here we define the system prompt for the Llama 4 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a303e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \\\n",
    "'''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "You will be provided with a block of code and the existing doucmentation that accompanies it.\n",
    "Simplify the given documentation, using the provided code as context, so that it is understandable\n",
    "to beginner programmers. Output absolutely nothing else besides the simplified documentation.\n",
    "Make sure to keep any documentation formatting codes present in the simplified documentation.\n",
    "If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "it further, feel free to keep the documentation as is. Here is the original documentation and code:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b523e6",
   "metadata": {},
   "source": [
    "Creating the pipeline for the Llama 2 model using the HuggingFace transformers library. Modified from the example here: https://huggingface.co/docs/transformers/en/model_doc/llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa4efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fadc72f9d84663a56458669eb757a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 50 files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169ab6648f354fb6ab200d863954aacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"meta-llama/Llama-4-Scout-17B-16E-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1bfaf",
   "metadata": {},
   "source": [
    "Testing the pipeline. Modified from examples given here: https://huggingface.co/docs/transformers/main/en/chat_templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6011ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Documentation:\n",
      "Extracts video ID from URL.\n",
      "\n",
      "Code:\n",
      "def get_vid_from_url(url):\n",
      "        \"\"\"Extracts video ID from URL.\n",
      "        \"\"\"\n",
      "        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n",
      "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n",
      "          parse_query_param(url, 'v') or \\\n",
      "          parse_query_param(parse_query_param(url, 'u'), 'v')\n",
      "\n",
      "Simplified Documentation:\n",
      "``` \n",
      "def get_vid_from_url(url):\n",
      "    \"\"\"\n",
      "    Extracts the video ID from a YouTube URL.\n",
      "\n",
      "    This function takes a YouTube URL as input and returns the video ID.\n",
      "    It supports various YouTube URL formats, including:\n",
      "    - youtu.be\n",
      "    - youtube.com/embed\n",
      "    - youtube.com/v\n",
      "    - youtube.com/watch\n",
      "    - URLs with a query parameter 'v'\n",
      "    \"\"\"\n",
      "    return match1(url, r'youtu\\.be/([^?/]+)') or \\\n",
      "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n",
      "          parse_query_param(url, 'v') or \\\n",
      "          parse_query_param(parse_query_param(url, 'u'), 'v')\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Documentation:\\n{dataset['test'][0]['func_documentation_string']}\\n\\nCode:\\n{dataset['test'][0]['func_code_string']}\"}\n",
    "]\n",
    "print(f\"Original Documentation:\\n{dataset['test'][0]['func_documentation_string']}\\n\")\n",
    "print(f\"Code:\\n{dataset['test'][0]['func_code_string']}\\n\")\n",
    "output = pipe(message, pad_token_id=pipe.tokenizer.eos_token_id, max_new_tokens=2000)\n",
    "print(\"Simplified Documentation:\\n\" + output[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da96447",
   "metadata": {},
   "source": [
    "Loading the evaluation model used for computing semantic similarity. Taken from example here: https://huggingface.co/tasks/sentence-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf2e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2f233",
   "metadata": {},
   "source": [
    "Running inference on the dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05b3770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 18%|█▊        | 9/50 [08:31<26:08, 38.25s/it]   You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 50/50 [44:46<00:00, 53.73s/it] \n"
     ]
    }
   ],
   "source": [
    "semantic_similarities = []\n",
    "metrics = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "for instance in tqdm(dataset_sample):\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Documentation:\\n{instance['func_documentation_string']}\\n\\nCode:\\n{instance['func_code_string']}\"}\n",
    "    ]\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    result = pipe(message, pad_token_id=pipe.tokenizer.eos_token_id, max_new_tokens=2000)[0]['generated_text'][-1]['content']\n",
    "\n",
    "    embedding_original = eval_model.encode(instance['func_documentation_string'], convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    semantic_similarities.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    metrics.add(predictions=result, references=instance['func_documentation_string'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d144bea",
   "metadata": {},
   "source": [
    "Summary statistics for semantic similarity results (alternative model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e295fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.700589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.208311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.032901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.665341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.742608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.848514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.933072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "count  50.000000\n",
       "mean    0.700589\n",
       "std     0.208311\n",
       "min    -0.032901\n",
       "25%     0.665341\n",
       "50%     0.742608\n",
       "75%     0.848514\n",
       "max     0.933072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(semantic_similarities).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07954701",
   "metadata": {},
   "source": [
    "ROUGE and METEOR results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08bf030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.40630260978545596,\n",
       " 'rouge2': 0.2399953505621984,\n",
       " 'rougeL': 0.3604821523347549,\n",
       " 'rougeLsum': 0.39214090448061795,\n",
       " 'meteor': 0.43048831851121055}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis532",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
