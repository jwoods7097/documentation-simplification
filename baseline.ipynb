{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e66bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4fe39",
   "metadata": {},
   "source": [
    "# Loading Dataset\n",
    "\n",
    "The dataset can be found at https://huggingface.co/datasets/code-search-net/code_search_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c363fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('code-search-net/code_search_net')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67f1a8",
   "metadata": {},
   "source": [
    "Here are the columns in the dataset. We will be using `func_documentation_string` for documentation and `func_code_string` for code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512d4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fbf88b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repository_name', 'func_path_in_repository', 'func_name',\n",
       "       'whole_func_string', 'language', 'func_code_string', 'func_code_tokens',\n",
       "       'func_documentation_string', 'func_documentation_tokens', 'split_name',\n",
       "       'func_code_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1984e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_training_sample = train_df.groupby('language', group_keys=False).sample(n=20)\n",
    "self_training_sample.to_excel('self_training_sample.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8d9ab",
   "metadata": {},
   "source": [
    "Getting a random sample from the test split to test our baseline model. We will increase the size once we finalize the experimental plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae0f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = random.choices(dataset['test'], k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026741f",
   "metadata": {},
   "source": [
    "# Testing the Baseline model\n",
    "\n",
    "Here we define the system prompt for the Llama 2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a303e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \\\n",
    "'''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "You will be provided with a block of code and the existing doucmentation that accompanies it.\n",
    "Simplify the given documentation, using the provided code as context, so that it is understandable\n",
    "to beginner programmers. Output absolutely nothing else besides the simplified documentation.\n",
    "Make sure to keep any documentation formatting codes present in the simplified documentation.\n",
    "If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "it further, feel free to keep the documentation as is. Here is the original documentation and code:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b523e6",
   "metadata": {},
   "source": [
    "Creating the pipeline for the Llama 2 model using the HuggingFace transformers library. Modified from the example here: https://huggingface.co/docs/transformers/en/model_doc/llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa4efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432f7420b0d441d19d816e8ee93c49c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1bfaf",
   "metadata": {},
   "source": [
    "Testing the pipeline. Modified from examples given here: https://huggingface.co/docs/transformers/main/en/chat_templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6011ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Documentation:\n",
      "Extracts video ID from URL.\n",
      "\n",
      "Code:\n",
      "def get_vid_from_url(url):\n",
      "        \"\"\"Extracts video ID from URL.\n",
      "        \"\"\"\n",
      "        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n",
      "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n",
      "          parse_query_param(url, 'v') or \\\n",
      "          parse_query_param(parse_query_param(url, 'u'), 'v')\n",
      "\n",
      "  Simplified documentation:\n",
      "\n",
      "This function extracts the video ID from a URL. It uses regular expressions to search for the video ID in various parts of the URL, including the domain name, query parameters, and the URL path. If the video ID is not found in any of these places, it falls back on parsing the query parameters or the URL path of the parent URL.\n",
      "\n",
      "Here are the specific patterns used by the function:\n",
      "\n",
      "* `youtu.be/([^?/]+)`: Matches the URL prefix \"youtu.be\" followed by any characters that are not a question mark or a forward slash.\n",
      "* `youtube.com/embed/([^/?]+)`: Matches the URL prefix \"youtube.com/embed\" followed by any characters that are not a question mark or a forward slash.\n",
      "* `youtube.com/v/([^/?]+)`: Matches the URL prefix \"youtube.com/v\" followed by any characters that are not a question mark or a forward slash.\n",
      "* `youtube.com/watch/([^/?]+)`: Matches the URL prefix \"youtube.com/watch\" followed by any characters that are not a question mark or a forward slash.\n",
      "* `parse_query_param(url, 'v')`: Parses the query parameters of the URL \"url\" and returns the value of the parameter with key \"v\".\n",
      "* `parse_query_param(parse_query_param(url, 'u'), 'v')`: This is a nested function call that parses the query parameters of the URL \"url\" and returns the value of the parameter with key \"v\". If the parameter is not found, it falls back on the outer function call.\n",
      "\n",
      "By using regular expressions and nested function calls, this function can extract the video ID from a wide range of URLs, including those with complex query parameters.\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Documentation:\\n{dataset['test'][0]['func_documentation_string']}\\n\\nCode:\\n{dataset['test'][0]['func_code_string']}\"}\n",
    "]\n",
    "print(f\"Original Documentation:\\n{dataset['test'][0]['func_documentation_string']}\\n\")\n",
    "print(f\"Code:\\n{dataset['test'][0]['func_code_string']}\\n\")\n",
    "print(pipe(message, pad_token_id=pipe.tokenizer.eos_token_id)[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da96447",
   "metadata": {},
   "source": [
    "Loading the evaluation model used for computing semantic similarity. Taken from example here: https://huggingface.co/tasks/sentence-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2f233",
   "metadata": {},
   "source": [
    "Running inference on the dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b3770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "  2%|▏         | 1/50 [00:06<04:55,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.0617e-02, -2.5245e-02, -3.3898e-02,  3.4955e-02, -7.8197e-02,\n",
      "        -4.5097e-02,  2.1003e-02, -3.5388e-03, -4.2873e-02, -1.6457e-02,\n",
      "        -2.1768e-02, -1.0718e-01, -1.4750e-02,  2.3852e-02,  7.9610e-02,\n",
      "        -2.7136e-02, -1.7002e-02,  1.4127e-02,  3.1038e-02, -4.9230e-02,\n",
      "         6.4198e-02,  1.0624e-01, -8.7202e-02,  3.1809e-02, -2.4426e-02,\n",
      "         3.1333e-02, -1.0073e-02,  9.0686e-03,  3.7630e-02,  1.5045e-02,\n",
      "         6.4684e-02, -4.9418e-02, -1.6244e-02,  1.0994e-01,  1.9740e-02,\n",
      "         6.8167e-02, -1.7478e-02,  3.1046e-02,  2.0097e-02, -6.5180e-02,\n",
      "         1.8099e-02, -3.5956e-02, -5.0890e-02, -2.6844e-02, -1.0052e-02,\n",
      "        -1.1673e-02,  2.1438e-02,  1.7858e-02, -8.2263e-02, -6.2854e-02,\n",
      "        -5.4827e-02, -9.7541e-02, -4.2843e-02, -5.2755e-03, -3.6599e-02,\n",
      "         3.7040e-03,  9.3160e-03,  1.9749e-02, -4.8249e-02, -1.1434e-03,\n",
      "        -1.1182e-01, -1.8309e-03, -4.6854e-02, -1.3499e-02, -5.2136e-02,\n",
      "         2.8388e-02,  2.2618e-02,  4.9271e-02,  1.9158e-02,  2.1116e-02,\n",
      "        -3.1421e-02,  3.2068e-02,  8.2887e-02,  5.2944e-02, -4.3345e-02,\n",
      "         3.8264e-02, -3.3677e-02,  6.1170e-02, -6.0460e-03, -5.3316e-02,\n",
      "         6.5417e-02,  6.5176e-02,  7.5359e-02,  8.0245e-02,  4.4697e-02,\n",
      "         9.1284e-02, -1.7147e-02,  4.0931e-02, -3.3155e-02, -2.0714e-02,\n",
      "        -9.3417e-02, -1.1430e-01,  2.9206e-02,  1.0879e-02, -8.9131e-03,\n",
      "         7.6031e-02,  8.4182e-03, -5.5681e-02, -4.1068e-06,  2.8458e-02,\n",
      "        -9.7010e-02,  3.7012e-02, -2.4850e-02, -4.2993e-02, -1.1088e-02,\n",
      "         2.6818e-02, -3.1242e-02, -4.1959e-02,  3.3834e-02, -5.8743e-02,\n",
      "         4.3485e-02,  7.2881e-02, -5.4049e-02, -1.1524e-01, -5.1384e-02,\n",
      "        -2.6925e-02,  2.7321e-02, -1.0595e-01,  8.5305e-02,  1.1006e-02,\n",
      "        -4.0087e-02,  2.4192e-02, -1.2516e-02, -1.7922e-03,  3.4031e-02,\n",
      "        -2.2959e-03,  5.2175e-03, -7.6301e-34, -4.9985e-02,  4.7617e-02,\n",
      "        -5.7300e-02, -2.7407e-03, -1.0079e-01, -4.1679e-02, -1.7276e-04,\n",
      "         3.3493e-02, -7.6107e-03,  3.0313e-02,  1.2215e-01, -1.3628e-01,\n",
      "         3.8090e-02, -5.0929e-02, -4.2785e-02,  1.3560e-02,  4.0008e-02,\n",
      "         5.9939e-02, -2.8603e-02,  3.9346e-03, -1.9380e-02,  1.1066e-01,\n",
      "        -2.9983e-02,  3.0989e-02,  7.2860e-03,  6.5668e-02, -3.3089e-03,\n",
      "        -1.3064e-01,  4.0705e-02,  1.0259e-02,  1.4395e-01, -1.2058e-01,\n",
      "         6.2587e-02, -1.4176e-02,  6.6443e-02, -6.4245e-02,  3.4190e-02,\n",
      "         3.6220e-02, -3.6061e-02, -4.0567e-02,  5.6501e-02, -3.4792e-03,\n",
      "         3.4088e-03,  8.8558e-02, -5.9566e-02,  4.2754e-02, -5.2607e-02,\n",
      "        -1.8798e-02,  3.7968e-02, -9.8969e-02,  2.7151e-02,  3.2198e-02,\n",
      "         1.6153e-02,  8.8339e-04,  2.9813e-02,  1.1893e-02, -2.3089e-02,\n",
      "         1.0359e-01,  6.4496e-03, -6.7881e-02, -4.9215e-02,  2.6347e-02,\n",
      "        -9.2057e-02,  4.8110e-02,  5.0810e-03, -6.0243e-02, -8.1126e-03,\n",
      "        -5.5021e-02,  4.7792e-02, -2.2220e-03, -3.0995e-02, -5.7771e-02,\n",
      "        -3.6580e-02, -1.3796e-02,  1.2131e-01, -3.1349e-02, -1.6796e-02,\n",
      "        -6.9623e-03,  1.1664e-02,  3.2033e-02, -6.2331e-02, -5.4068e-02,\n",
      "         5.9575e-02,  3.4672e-02, -1.5026e-02,  2.3718e-02, -4.5881e-02,\n",
      "         8.4672e-03, -1.5514e-02, -3.2377e-02,  3.6694e-02, -2.1741e-02,\n",
      "        -1.0293e-01, -1.4972e-02,  3.2901e-02, -1.7997e-33,  6.0334e-02,\n",
      "         3.5081e-02, -1.2015e-01,  6.8557e-02, -2.7106e-02, -3.2760e-02,\n",
      "        -7.5606e-03, -6.3518e-03, -2.4551e-02,  4.8041e-03, -5.8188e-03,\n",
      "         5.9920e-03, -3.5951e-02,  5.0120e-02,  1.6636e-02,  5.7366e-02,\n",
      "        -6.9903e-02, -6.2536e-02, -7.2739e-03,  4.3023e-02, -6.2369e-03,\n",
      "         4.3654e-02,  4.2639e-02, -3.8241e-02,  2.1753e-02,  6.0168e-03,\n",
      "        -5.9467e-03,  1.1630e-01,  2.6996e-02,  6.3267e-02, -4.7522e-02,\n",
      "         4.3508e-02, -1.3829e-02, -8.3726e-02, -1.3491e-01, -4.1233e-03,\n",
      "        -1.6615e-02,  6.1398e-02, -1.8615e-02,  4.9857e-02,  3.1889e-02,\n",
      "         1.7877e-02, -9.3498e-02, -6.6340e-03, -4.1200e-02, -9.3811e-02,\n",
      "         2.9241e-03, -9.0833e-03,  1.1201e-02,  4.2816e-02, -6.5214e-02,\n",
      "        -4.2556e-02, -6.3284e-02, -3.2252e-02,  4.5618e-02, -2.4636e-02,\n",
      "         7.9116e-02, -6.2707e-02, -9.6930e-02,  3.5501e-02, -3.8019e-03,\n",
      "        -2.2257e-02,  4.3779e-02,  6.8198e-02,  6.1557e-02, -2.8202e-02,\n",
      "        -8.6651e-02, -3.8648e-02,  5.9731e-02, -1.1842e-01,  3.4124e-02,\n",
      "         4.3465e-02, -6.8513e-02, -6.9675e-03, -8.9786e-03,  5.0644e-02,\n",
      "         6.9662e-02,  7.3387e-02,  3.4344e-02,  3.6494e-02,  2.8032e-02,\n",
      "         1.1825e-02,  7.8466e-03,  6.7341e-02,  6.7651e-02, -4.6819e-02,\n",
      "         3.8502e-02,  7.9093e-02, -4.3847e-02, -3.4578e-03,  2.9452e-02,\n",
      "         5.9976e-02,  5.5556e-02, -2.6387e-02, -5.7207e-02, -3.2596e-08,\n",
      "        -1.0144e-01, -6.5236e-02,  6.4867e-03,  2.7302e-02,  1.7166e-03,\n",
      "         5.0015e-02, -6.0564e-04,  1.6462e-02, -2.9037e-02,  1.1337e-02,\n",
      "        -1.6827e-02, -4.5794e-02,  2.9566e-02, -2.8995e-02,  3.8892e-02,\n",
      "        -6.9317e-03,  5.3391e-02,  9.9183e-02, -9.8877e-02,  9.3805e-02,\n",
      "        -2.9600e-02, -1.7979e-02, -5.0624e-02,  4.1699e-02, -3.0652e-03,\n",
      "        -1.7931e-02, -7.4129e-03, -7.5426e-02, -6.1129e-03,  3.5852e-02,\n",
      "        -5.4336e-03,  1.0223e-01, -4.0851e-02,  2.7445e-02,  1.4668e-02,\n",
      "         9.3379e-02,  5.2775e-03, -3.4859e-03,  1.9336e-02,  6.9157e-02,\n",
      "         3.6165e-02, -1.5924e-02, -7.7324e-02,  7.4790e-03,  4.3714e-02,\n",
      "         4.8693e-02, -4.2667e-03, -7.1664e-02,  1.3136e-01,  1.4081e-02,\n",
      "         6.0088e-03,  1.9594e-02, -8.2002e-03,  1.5658e-02, -5.0976e-02,\n",
      "        -2.6295e-02,  5.0468e-02, -1.1113e-02,  1.2558e-02, -2.0604e-02,\n",
      "        -1.8169e-02, -8.1002e-03,  7.3317e-02,  2.0920e-02], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:10<04:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.0239e-02,  1.3712e-01, -6.9470e-03,  1.5242e-02, -5.1226e-03,\n",
      "         1.6771e-02,  9.9646e-03,  5.7874e-02,  6.5670e-03,  1.5901e-02,\n",
      "         7.4522e-02, -1.2004e-01,  6.4690e-02, -3.5782e-03,  6.9950e-02,\n",
      "         8.6913e-02, -5.2090e-02,  3.0828e-02,  1.6852e-03,  4.6658e-02,\n",
      "         1.1616e-01,  7.5936e-02, -6.7552e-02, -3.6469e-02,  5.4639e-02,\n",
      "         3.1610e-02,  6.8702e-02,  4.3317e-02,  7.3390e-02,  1.1406e-03,\n",
      "         2.5449e-02,  2.6494e-02,  6.3689e-02, -9.0704e-03,  1.1250e-02,\n",
      "         8.3471e-02, -8.4939e-02, -5.8509e-02, -1.1904e-02,  1.9717e-02,\n",
      "        -4.3615e-02, -7.6456e-03,  3.9391e-02, -1.4664e-02, -1.6879e-02,\n",
      "        -9.7906e-03,  9.1812e-02, -7.4593e-02, -2.7284e-02, -1.5149e-03,\n",
      "         1.9102e-02, -7.1336e-03, -4.3299e-02, -2.6872e-03, -6.2507e-02,\n",
      "         3.3082e-02, -6.8758e-02, -7.7160e-02, -6.0820e-02, -7.4388e-02,\n",
      "        -2.5024e-02,  1.1139e-02,  6.0829e-02,  9.2320e-03,  2.6255e-04,\n",
      "        -2.0452e-03, -1.1974e-01, -1.2278e-02,  7.0765e-03, -5.2321e-02,\n",
      "        -6.4847e-02, -2.7451e-02, -3.3245e-02,  3.7819e-02,  4.9733e-02,\n",
      "        -5.4514e-02, -2.5497e-02, -4.9180e-02,  7.6851e-02,  6.3516e-03,\n",
      "         5.5562e-02,  2.0329e-02, -7.9915e-02, -8.9251e-03,  3.6909e-03,\n",
      "         9.1210e-02,  5.7556e-02,  2.2626e-02,  6.4964e-02,  1.6291e-02,\n",
      "        -4.1407e-02, -5.1708e-02, -1.5449e-02,  1.7981e-02,  7.4423e-03,\n",
      "         5.3378e-02, -2.2048e-02, -6.8547e-02,  1.5752e-02,  5.9729e-02,\n",
      "         3.7647e-02,  1.2383e-01, -9.7537e-02, -1.5224e-01, -1.1017e-01,\n",
      "        -8.1524e-02,  4.7057e-02,  3.8355e-02, -1.3121e-03,  1.1324e-02,\n",
      "         2.7221e-02, -3.7567e-02, -4.3802e-02, -3.7531e-03, -3.0327e-02,\n",
      "         5.8390e-02,  6.2583e-02, -4.9820e-02, -4.0466e-02, -2.2173e-02,\n",
      "         9.5386e-02,  1.8285e-02, -6.0128e-02,  4.5251e-02, -1.4880e-02,\n",
      "        -1.7671e-02,  2.8377e-02, -2.7952e-33, -6.1689e-02,  2.5494e-02,\n",
      "         2.2830e-02,  5.0823e-02,  7.8457e-04, -3.6065e-02,  2.5368e-02,\n",
      "        -2.2254e-03, -1.7873e-02, -5.0771e-03, -4.9949e-02, -2.7789e-02,\n",
      "         2.7231e-02, -2.7161e-02, -2.2630e-03,  4.5503e-02, -3.0240e-02,\n",
      "         5.7045e-02,  3.5464e-02,  5.1309e-04,  3.4255e-02, -7.5771e-03,\n",
      "         1.8783e-02, -3.1997e-02, -8.0241e-02,  2.1440e-02,  1.6649e-02,\n",
      "        -1.1731e-02,  2.2142e-02, -7.2498e-02,  2.8818e-02, -7.4612e-02,\n",
      "        -5.8161e-02,  1.0594e-01,  5.1364e-02,  8.7325e-02,  1.4446e-02,\n",
      "        -5.8419e-02,  8.5299e-02,  7.0074e-02, -9.4708e-02,  1.2213e-02,\n",
      "         8.3132e-02,  1.3328e-02,  6.9005e-02, -7.6622e-02, -2.5281e-02,\n",
      "         7.0406e-02,  1.0607e-02, -1.4631e-02, -8.6763e-03,  4.6357e-02,\n",
      "         6.8034e-02, -5.0763e-03, -3.0283e-02,  6.5739e-02, -5.2055e-02,\n",
      "         1.0363e-01, -3.7601e-02, -8.1459e-03, -1.9217e-02,  4.0668e-02,\n",
      "         4.9054e-02, -2.1148e-02, -5.6726e-03, -4.9460e-02,  4.7337e-02,\n",
      "        -9.8818e-02,  1.3261e-02,  1.1354e-02, -1.0942e-02,  9.0477e-03,\n",
      "        -9.6376e-03, -9.4119e-02,  2.5260e-02, -4.8128e-02, -4.8566e-02,\n",
      "        -8.2706e-02, -2.8048e-02, -3.0938e-04, -2.9335e-02,  3.2423e-03,\n",
      "         2.6118e-02,  7.7033e-02,  1.3150e-01, -2.7550e-02,  7.7963e-03,\n",
      "        -6.3993e-02, -2.8061e-02, -3.8700e-02,  2.9944e-02, -6.3596e-02,\n",
      "        -8.9850e-02, -4.1010e-02,  7.9556e-02,  2.3793e-33, -8.3900e-02,\n",
      "         2.2789e-02, -2.9098e-02, -9.0362e-02,  1.1313e-02, -7.5298e-02,\n",
      "         3.0221e-02, -5.8944e-02, -1.6974e-02,  6.7243e-02, -5.9585e-02,\n",
      "        -5.2254e-03, -6.9800e-02, -2.8375e-02, -1.8938e-02,  9.1610e-03,\n",
      "        -1.0498e-02,  3.2907e-02, -7.8654e-03, -3.7773e-02, -1.6075e-02,\n",
      "         1.0100e-01,  1.1939e-02,  5.4448e-03, -3.2000e-02,  4.0247e-02,\n",
      "         4.9127e-02,  8.4656e-02, -3.1709e-02,  9.9988e-03, -2.9364e-02,\n",
      "        -2.0096e-03, -1.8415e-02,  6.0835e-02, -1.3851e-02, -3.6144e-02,\n",
      "         4.1504e-02,  3.3243e-03,  4.9330e-02,  2.1478e-02, -2.9574e-02,\n",
      "        -5.4357e-02,  8.2113e-02, -3.4983e-03,  1.7748e-02, -2.3024e-02,\n",
      "         8.7789e-03,  2.7148e-02,  5.9385e-02,  1.1493e-02, -2.9896e-02,\n",
      "        -2.9778e-03, -1.6292e-01,  2.8279e-02, -3.6622e-02, -9.2355e-03,\n",
      "        -6.2455e-02, -3.5419e-02,  7.4165e-03, -6.1637e-02, -4.4720e-02,\n",
      "         1.8740e-02,  7.0790e-02,  7.1105e-02,  2.9504e-02, -2.9562e-02,\n",
      "        -3.1308e-03, -1.0610e-02, -5.9768e-02,  3.3352e-03,  8.7019e-02,\n",
      "         5.6349e-02,  2.5728e-02, -2.7125e-02,  6.0032e-02, -7.4073e-02,\n",
      "         5.2775e-02,  3.0451e-02,  1.0556e-02, -3.5801e-02, -1.7714e-02,\n",
      "         9.7646e-03,  7.8431e-03, -3.7380e-02,  1.8271e-02, -7.9617e-02,\n",
      "        -8.1446e-03,  7.5574e-02, -4.7951e-02, -1.8242e-02,  1.8540e-02,\n",
      "         7.4837e-02,  1.0769e-02,  8.7827e-03, -4.2567e-02, -1.7325e-08,\n",
      "        -1.0971e-01,  3.1806e-02, -3.2981e-02, -8.4143e-02,  3.1087e-02,\n",
      "         1.0833e-01,  2.9946e-02, -2.1888e-02,  4.3567e-02, -3.1193e-02,\n",
      "         6.1619e-02, -7.4065e-02,  1.3647e-02, -7.3496e-02,  5.5300e-02,\n",
      "         5.5478e-02, -5.9230e-03,  3.6849e-02, -7.4923e-02, -6.2148e-02,\n",
      "        -6.6154e-03, -1.6704e-02, -6.5984e-02,  5.4233e-02,  8.3239e-02,\n",
      "        -1.2415e-02, -3.2972e-02, -2.4268e-02,  4.2465e-02,  3.1276e-02,\n",
      "         4.1749e-03,  6.2657e-02, -1.5055e-02,  3.4588e-02, -7.7211e-02,\n",
      "        -7.5605e-03,  7.1462e-02,  4.0295e-02, -6.5540e-03,  6.7214e-02,\n",
      "        -2.1094e-02, -2.1915e-02, -4.0149e-02,  9.4271e-03,  2.7123e-02,\n",
      "        -4.4200e-03,  6.2492e-03, -5.3970e-02,  1.4550e-01,  2.1843e-02,\n",
      "         2.3542e-02, -6.2161e-02,  1.7075e-02, -5.2007e-02, -1.7832e-02,\n",
      "        -2.9775e-02, -1.4129e-02,  1.3539e-03,  3.6941e-02,  8.6591e-02,\n",
      "        -2.1671e-02,  6.6120e-02,  1.5017e-01,  1.4855e-02], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:14<05:53,  7.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset_sample):\n\u001b[1;32m      5\u001b[0m     message \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[1;32m      7\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumentation:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minstance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc_documentation_string\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCode:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minstance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc_code_string\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      8\u001b[0m     ]\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     embedding_original \u001b[38;5;241m=\u001b[39m eval_model\u001b[38;5;241m.\u001b[39mencode(instance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc_documentation_string\u001b[39m\u001b[38;5;124m'\u001b[39m], convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m     embedding_predicted \u001b[38;5;241m=\u001b[39m eval_model\u001b[38;5;241m.\u001b[39mencode(result, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/transformers/pipelines/text_generation.py:267\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    263\u001b[0m     text_inputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, KeyDataset) \u001b[38;5;28;01mif\u001b[39;00m is_torch_available() \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m    264\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text_inputs[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text_inputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         chats \u001b[38;5;241m=\u001b[39m [Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs]  \u001b[38;5;66;03m# 🐈 🐈 🐈\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/transformers/pipelines/base.py:1302\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         )\n\u001b[1;32m   1300\u001b[0m     )\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/transformers/pipelines/base.py:1309\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1308\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1309\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1310\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/transformers/pipelines/base.py:1209\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1208\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1209\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/transformers/pipelines/text_generation.py:370\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    368\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 370\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/transformers/generation/utils.py:3195\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3192\u001b[0m unfinished_sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(batch_size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3193\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_initial_cache_position(input_ids, model_kwargs)\n\u001b[0;32m-> 3195\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_unfinished_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis_peer_finished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   3198\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[1;32m   3199\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   3201\u001b[0m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cis532/lib/python3.9/site-packages/transformers/generation/utils.py:2413\u001b[0m, in \u001b[0;36mGenerationMixin._has_unfinished_sequences\u001b[0;34m(self, this_peer_finished, synced_gpus, device, cur_len, max_length)\u001b[0m\n\u001b[1;32m   2411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m this_peer_finished_flag\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   2412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2413\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "semantic_similarities = []\n",
    "metrics = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "for instance in tqdm(dataset_sample):\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Documentation:\\n{instance['func_documentation_string']}\\n\\nCode:\\n{instance['func_code_string']}\"}\n",
    "    ]\n",
    "\n",
    "    result = pipe(message, pad_token_id=pipe.tokenizer.eos_token_id)[0]['generated_text'][-1]['content']\n",
    "\n",
    "    embedding_original = eval_model.encode(instance['func_documentation_string'], convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    semantic_similarities.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    metrics.add(predictions=result, references=instance['func_documentation_string'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d144bea",
   "metadata": {},
   "source": [
    "Summary statistics for semantic similarity results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e295fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.665009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.182714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.088799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.558814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.683454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.791257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.926352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "count  50.000000\n",
       "mean    0.665009\n",
       "std     0.182714\n",
       "min     0.088799\n",
       "25%     0.558814\n",
       "50%     0.683454\n",
       "75%     0.791257\n",
       "max     0.926352"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(semantic_similarities).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07954701",
   "metadata": {},
   "source": [
    "ROUGE and METEOR results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b08bf030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.280522090651527,\n",
       " 'rouge2': 0.19042346879502914,\n",
       " 'rougeL': 0.24326669815314184,\n",
       " 'rougeLsum': 0.27162905999224796,\n",
       " 'meteor': 0.3745646064192065}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis532",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
