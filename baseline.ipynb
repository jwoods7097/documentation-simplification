{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e66bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4fe39",
   "metadata": {},
   "source": [
    "# Loading Dataset\n",
    "\n",
    "The dataset can be found at https://huggingface.co/datasets/Fsoft-AIC/the-vault-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c363fcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3629a961514fb2835dd26cca9f6ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "python-00000-of-00001.parquet:   0%|          | 0.00/30.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279444e3428c40c290adfccd10cc8b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "c-00000-of-00001.parquet:   0%|          | 0.00/25.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962bcf6f53e34767b5b0419e03f7f761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "c_sharp-00000-of-00001.parquet:   0%|          | 0.00/18.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3e6ea098744a44bc67ef7a3613937d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cpp-00000-of-00001.parquet:   0%|          | 0.00/23.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd9df8e10204f41bd90c5d9b1da2990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "go-00000-of-00001.parquet:   0%|          | 0.00/19.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bb208685674697aad3386a91c01eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "java-00000-of-00001.parquet:   0%|          | 0.00/19.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c39396e465e43948a34282d0b50f4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "javascript-00000-of-00001.parquet:   0%|          | 0.00/26.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3d428821e7429d928db75694dd06aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "php-00000-of-00001.parquet:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125763cb076d48b98d51c7e5d1e3b7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ruby-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198ee7495989476ab7b956fb09ef0ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rust-00000-of-00001.parquet:   0%|          | 0.00/29.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aae5334d2454b09a5374ac83e9a562b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Fsoft-AIC/the-vault-function\", split_set=[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67f1a8",
   "metadata": {},
   "source": [
    "Here are the columns in the dataset. We will be using `original_docstring` for documentation and `original_string` for code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512d4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbf88b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hexsha', 'repo', 'path', 'license', 'language', 'identifier',\n",
       "       'return_type', 'original_string', 'original_docstring', 'docstring',\n",
       "       'docstring_tokens', 'code', 'code_tokens', 'short_docstring',\n",
       "       'short_docstring_tokens', 'comment', 'parameters', 'docstring_params'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1984e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_training_sample = train_df.groupby('language', group_keys=False).sample(n=20)\n",
    "self_training_sample.to_excel('self_training_sample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928c895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'C#', 'C++', 'Go', 'Java', 'JavaScript', 'PHP', 'Python',\n",
       "       'Ruby', 'Rust'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_training_sample['language'].unique()\n",
    "# I'm doing C++, Go, Java, Ruby, and Rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a641eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// A matching Chrome app replaces the created URL app.\n",
      "IN_PROC_BROWSER_TEST_F(DriveAppProviderTest, MatchingChromeAppInstalled) {\n",
      "  // Prepare a Drive app that matches the not-yet-installed kChromeAppId.\n",
      "  fake_drive_service()->AddApp(\n",
      "      kDriveAppId, kDriveAppName, kChromeAppId, kLaunchUrl);\n",
      "  RefreshDriveAppRegistry();\n",
      "  WaitForPendingDriveAppConverters();\n",
      "\n",
      "  // An Url app should be created.\n",
      "  const Extension* url_app =\n",
      "      ExtensionRegistry::Get(profile())->GetExtensionById(\n",
      "          mapping()->GetChromeApp(kDriveAppId), ExtensionRegistry::EVERYTHING);\n",
      "  EXPECT_TRUE(url_app->is_hosted_app());\n",
      "  EXPECT_TRUE(url_app->from_bookmark());\n",
      "\n",
      "  const std::string url_app_id = url_app->id();\n",
      "  EXPECT_NE(kChromeAppId, url_app_id);\n",
      "  EXPECT_EQ(url_app_id, mapping()->GetChromeApp(kDriveAppId));\n",
      "  EXPECT_TRUE(mapping()->IsChromeAppGenerated(url_app_id));\n",
      "\n",
      "  // Installs a chrome app with matching id.\n",
      "  InstallChromeApp(0);\n",
      "\n",
      "  // The Drive app should be mapped to chrome app.\n",
      "  EXPECT_EQ(kChromeAppId, mapping()->GetChromeApp(kDriveAppId));\n",
      "  EXPECT_FALSE(mapping()->IsChromeAppGenerated(kChromeAppId));\n",
      "\n",
      "  // Url app should be auto uninstalled.\n",
      "  EXPECT_FALSE(ExtensionRegistry::Get(profile())->GetExtensionById(\n",
      "      url_app_id, ExtensionRegistry::EVERYTHING));\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Autogenerated instance field setter\n",
      "// Set instance field: public Zenject.IProvider Provider\n",
      "void Zenject::Internal::LookupId::_set_Provider(Zenject::IProvider* value) {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"Zenject::Internal::LookupId::_set_Provider\");\n",
      "  auto ___internal__instance = this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"Provider\"))->offset;\n",
      "  *reinterpret_cast<Zenject::IProvider**>(reinterpret_cast<char*>(this) + ___internal__field__offset) = value;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Decompose with OpenCL, compose with CPU\n",
      "TEST(Task_Wavelet_OpenCL, Decompose1D) {\n",
      "  if (!cv::ocl::haveOpenCL()) GTEST_SKIP();\n",
      "  cv::ocl::setUseOpenCL(true);\n",
      "\n",
      "  cv::Mat input(1, 16, CV_32FC2);\n",
      "  input = cv::Vec2f(0, 0);\n",
      "  input(cv::Rect(8, 0, 8, 1)) = cv::Vec2f(1.0f, 0.0f);\n",
      "\n",
      "  cv::Mat wavelet(1, 16, CV_32FC2);\n",
      "\n",
      "  {\n",
      "    cv::UMat uinput(1, 16, CV_32FC2);\n",
      "    input.copyTo(uinput);\n",
      "\n",
      "    cv::UMat uwavelet(1, 16, CV_32FC2);\n",
      "    Wavelet<cv::UMat>::decompose_1d(uinput, uwavelet, false);\n",
      "    uwavelet.copyTo(wavelet);\n",
      "  }\n",
      "\n",
      "  cv::Mat composed(1, 16, CV_32FC2);\n",
      "  Wavelet<cv::Mat>::compose_1d(wavelet, composed, false);\n",
      "\n",
      "  for (int i = 0; i < 16; i++)\n",
      "  {\n",
      "    float delta_re = std::abs(input.at<cv::Vec2f>(i)[0] - composed.at<cv::Vec2f>(i)[0]);\n",
      "    float delta_im = std::abs(input.at<cv::Vec2f>(i)[1] - composed.at<cv::Vec2f>(i)[1]);\n",
      "\n",
      "    ASSERT_LE(delta_re, 0.001f);\n",
      "    ASSERT_LE(delta_im, 0.001f);\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "//  There is almost always an automation client.  Usually the Address Bar\n",
      "//  and Explorer Band are watching us.  Sometimes MSHTML is watching, too.\n",
      "HRESULT CDefView::NotifyAutomation(DISPID dispid)\n",
      "{\n",
      "    return IUnknown_CPContainerInvokeParam(m_pauto, DIID_DShellFolderViewEvents,\n",
      "                                           dispid, NULL, 0);\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Autogenerated instance field setter\n",
      "// Set instance field: private UnityEngine.UI.Button _buyPackButton\n",
      "void GlobalNamespace::StandardLevelBuyInfoView::_set__buyPackButton(UnityEngine::UI::Button* value) {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"GlobalNamespace::StandardLevelBuyInfoView::_set__buyPackButton\");\n",
      "  auto ___internal__instance = this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"_buyPackButton\"))->offset;\n",
      "  *reinterpret_cast<UnityEngine::UI::Button**>(reinterpret_cast<char*>(this) + ___internal__field__offset) = value;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "/// checks for environment variables existence.\n",
      "// @string name environment variable's name.\n",
      "// @return boolean or nil. (error)\n",
      "// @return error message.\n",
      "// @function has\n",
      "int Environment::has(lua_State* L)\n",
      "{\n",
      "    int rv = 0;\n",
      "    try\n",
      "    {\n",
      "        const char* key = luaL_checkstring(L, 1);\n",
      "        bool result = Poco::Environment::has(key);\n",
      "        lua_pushboolean(L, result);\n",
      "        rv = 1;\n",
      "    }\n",
      "    catch (const Poco::Exception& e)\n",
      "    {\n",
      "        rv = pushPocoException(L, e);\n",
      "    }\n",
      "    catch (...)\n",
      "    {\n",
      "        rv = pushUnknownException(L);\n",
      "    }\n",
      "    \n",
      "    return rv;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "/**\n",
      " * Perform a network request on JVM\n",
      " *\n",
      " * 1. Cast userdata to the network transport\n",
      " * 2. Transform core request to JVM request\n",
      " * 3. Perform request\n",
      " * 4. Transform JVM response to core response\n",
      " */\n",
      "static void network_request_lambda_function(void* userdata,\n",
      "                                            const realm_http_request_t request,\n",
      "                                            void* request_context) {\n",
      "    auto jenv = get_env(true);\n",
      "\n",
      "    // Initialize pointer to JVM class and methods\n",
      "    jobject network_transport = static_cast<jobject>(userdata);\n",
      "\n",
      "    try {\n",
      "        jclass response_callback_class = jenv->FindClass(\n",
      "                \"io/realm/internal/interop/sync/ResponseCallbackImpl\");\n",
      "        static jmethodID response_callback_constructor = jenv->GetMethodID(response_callback_class,\n",
      "                                                                           \"<init>\",\n",
      "                                                                           \"(Lio/realm/internal/interop/sync/NetworkTransport;J)V\");\n",
      "        jobject response_callback = jenv->NewObject(response_callback_class,\n",
      "                                                    response_callback_constructor,\n",
      "                                                    reinterpret_cast<jobject>(userdata),\n",
      "                                                    reinterpret_cast<jlong>(request_context));\n",
      "\n",
      "        send_request_via_jvm_transport(jenv, network_transport, request, response_callback);\n",
      "    } catch (std::runtime_error &e) {\n",
      "        // Runtime exception while processing the request/response\n",
      "        realm_http_response_t response_error;\n",
      "        // FIXME: validate we propagate the custom codes as an actual exception to the user\n",
      "        // see: https://github.com/realm/realm-kotlin/issues/451\n",
      "        response_error.custom_status_code = -4;\n",
      "        response_error.num_headers = 0;\n",
      "        response_error.body_size = 0;\n",
      "\n",
      "        realm_http_transport_complete_request(request_context, &response_error);\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "//------------------------------------------------------------------------------\n",
      "// Update the sum and count fields for average if input is not null.\n",
      "// rowIn(in)  - Row to be included in aggregation.\n",
      "// colIn(in)  - column in the input row group\n",
      "// colOut(in) - column in the output row group stores the count\n",
      "// colAux(in) - column in the output row group stores the sum(x)\n",
      "// colAux + 1 - column in the output row group stores the sum(x**2)\n",
      "//------------------------------------------------------------------------------\n",
      "void RowAggregation::doStatistics(const Row& rowIn, int64_t colIn, int64_t colOut, int64_t colAux)\n",
      "{\n",
      "    int colDataType = (fRowGroupIn.getColTypes())[colIn];\n",
      "\n",
      "    if (isNull(&fRowGroupIn, rowIn, colIn) == true)\n",
      "        return;\n",
      "\n",
      "    long double valIn = 0.0;\n",
      "\n",
      "    switch (colDataType)\n",
      "    {\n",
      "        case execplan::CalpontSystemCatalog::TINYINT:\n",
      "        case execplan::CalpontSystemCatalog::SMALLINT:\n",
      "        case execplan::CalpontSystemCatalog::MEDINT:\n",
      "        case execplan::CalpontSystemCatalog::INT:\n",
      "        case execplan::CalpontSystemCatalog::BIGINT:\n",
      "            valIn = (long double) rowIn.getIntField(colIn);\n",
      "            break;\n",
      "\n",
      "        case execplan::CalpontSystemCatalog::DECIMAL:   // handle scale later\n",
      "        case execplan::CalpontSystemCatalog::UDECIMAL:  // handle scale later\n",
      "            if (LIKELY(fRowGroupIn.getColumnWidth(colIn) == datatypes::MAXDECIMALWIDTH))\n",
      "            {\n",
      "                // To save from unaligned memory\n",
      "                datatypes::TSInt128 val128In(rowIn.getBinaryField<int128_t>(colIn));\n",
      "                valIn =  static_cast<long double>(val128In.toTFloat128());\n",
      "            }\n",
      "            else if (fRowGroupIn.getColumnWidth(colIn) <= datatypes::MAXLEGACYWIDTH)\n",
      "            {\n",
      "                valIn = (long double) rowIn.getIntField(colIn);\n",
      "            }\n",
      "            else\n",
      "            {\n",
      "                idbassert(false);\n",
      "            }\n",
      "            break;\n",
      "\n",
      "        case execplan::CalpontSystemCatalog::UTINYINT:\n",
      "        case execplan::CalpontSystemCatalog::USMALLINT:\n",
      "        case execplan::CalpontSystemCatalog::UMEDINT:\n",
      "        case execplan::CalpontSystemCatalog::UINT:\n",
      "        case execplan::CalpontSystemCatalog::UBIGINT:\n",
      "            valIn = (long double) rowIn.getUintField(colIn);\n",
      "            break;\n",
      "\n",
      "        case execplan::CalpontSystemCatalog::DOUBLE:\n",
      "        case execplan::CalpontSystemCatalog::UDOUBLE:\n",
      "            valIn = (long double) rowIn.getDoubleField(colIn);\n",
      "            break;\n",
      "\n",
      "        case execplan::CalpontSystemCatalog::FLOAT:\n",
      "        case execplan::CalpontSystemCatalog::UFLOAT:\n",
      "            valIn = (long double) rowIn.getFloatField(colIn);\n",
      "            break;\n",
      "\n",
      "        case execplan::CalpontSystemCatalog::LONGDOUBLE:\n",
      "            valIn = rowIn.getLongDoubleField(colIn);\n",
      "            break;\n",
      "\n",
      "        default:\n",
      "            std::ostringstream errmsg;\n",
      "            errmsg << \"RowAggregation: no average for data type: \" << colDataType;\n",
      "            cerr << errmsg.str() << endl;\n",
      "            throw logging::QueryDataExcept(errmsg.str(), logging::aggregateFuncErr);\n",
      "            break;\n",
      "    }\n",
      "\n",
      "    fRow.setDoubleField(fRow.getDoubleField(colOut) + 1.0, colOut);\n",
      "    fRow.setLongDoubleField(fRow.getLongDoubleField(colAux) + valIn, colAux);\n",
      "    fRow.setLongDoubleField(fRow.getLongDoubleField(colAux + 1) + valIn * valIn, colAux + 1);\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Completed includes\n",
      "// Autogenerated instance field getter\n",
      "// Get instance field: public readonly Signal signal\n",
      "GlobalNamespace::Signal* GlobalNamespace::TutorialSongController::TutorialObjectSpawnData::_get_signal() {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"GlobalNamespace::TutorialSongController::TutorialObjectSpawnData::_get_signal\");\n",
      "  auto ___internal__instance = this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"signal\"))->offset;\n",
      "  return *reinterpret_cast<GlobalNamespace::Signal**>(reinterpret_cast<char*>(this) + ___internal__field__offset);\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Autogenerated instance field setter\n",
      "// Set instance field: private readonly UnityEngine.Animator _animator\n",
      "void Zenject::AnimatorInstaller::_set__animator(UnityEngine::Animator* value) {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"Zenject::AnimatorInstaller::_set__animator\");\n",
      "  auto ___internal__instance = this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"_animator\"))->offset;\n",
      "  *reinterpret_cast<UnityEngine::Animator**>(reinterpret_cast<char*>(this) + ___internal__field__offset) = value;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Autogenerated instance field getter\n",
      "// Get instance field: System.String[] m_ProviderIds\n",
      "::Array<::Il2CppString*>* UnityEngine::AddressableAssets::ResourceLocators::ContentCatalogData::_get_m_ProviderIds() {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"UnityEngine::AddressableAssets::ResourceLocators::ContentCatalogData::_get_m_ProviderIds\");\n",
      "  auto ___internal__instance = this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"m_ProviderIds\"))->offset;\n",
      "  return *reinterpret_cast<::Array<::Il2CppString*>**>(reinterpret_cast<char*>(this) + ___internal__field__offset);\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Autogenerated instance field getter\n",
      "// Get instance field: private System.Boolean isWriterInProgress\n",
      "bool System::Collections::Hashtable::_get_isWriterInProgress() {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"System::Collections::Hashtable::_get_isWriterInProgress\");\n",
      "  auto ___internal__instance = this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"isWriterInProgress\"))->offset;\n",
      "  return *reinterpret_cast<bool*>(reinterpret_cast<char*>(this) + ___internal__field__offset);\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Autogenerated instance field setter\n",
      "// Set instance field: private System.UInt32[] _sum0\n",
      "void Org::BouncyCastle::Crypto::Engines::XteaEngine::_set__sum0(::Array<uint>* value) {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"Org::BouncyCastle::Crypto::Engines::XteaEngine::_set__sum0\");\n",
      "  auto ___internal__instance = this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"_sum0\"))->offset;\n",
      "  *reinterpret_cast<::Array<uint>**>(reinterpret_cast<char*>(this) + ___internal__field__offset) = value;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "/*\n",
      " * Delete a mutation level, accepting random mutation types and checking mutation resistance.\n",
      " * This will not delete temporary or innate mutations.\n",
      " *\n",
      " * @param which_mutation    a mutation, including random\n",
      " * @param reason            the reason for deletion\n",
      " * @param failMsg           whether to message the player on failure\n",
      " * @param force_mutation    whether to try to override certain cases where the mutation would otherwise fail\n",
      " * @param god_gift          is the mutation a god gift?  Will also override certain cases.\n",
      " * @param disallow_mismatch for random mutations, do we override good/bad designations in `which_mutation`? (??)\n",
      " *\n",
      " * @return true iff a mutation was applied.\n",
      " */\n",
      "bool delete_mutation(mutation_type which_mutation, const string &reason,\n",
      "                     bool failMsg,\n",
      "                     bool force_mutation, bool god_gift,\n",
      "                     bool disallow_mismatch)\n",
      "{\n",
      "    god_gift |= crawl_state.is_god_acting();\n",
      "\n",
      "    mutation_type mutat = which_mutation;\n",
      "\n",
      "    if (!force_mutation)\n",
      "    {\n",
      "        if (!god_gift)\n",
      "        {\n",
      "            if (you.get_mutation_level(MUT_MUTATION_RESISTANCE) > 1\n",
      "                && (you.get_mutation_level(MUT_MUTATION_RESISTANCE) == 3\n",
      "                    || coinflip()))\n",
      "            {\n",
      "                if (failMsg)\n",
      "                    mprf(MSGCH_MUTATION, \"You feel rather odd for a moment.\");\n",
      "                return false;\n",
      "            }\n",
      "        }\n",
      "\n",
      "        if (undead_mutation_rot())\n",
      "            return false;\n",
      "    }\n",
      "\n",
      "    if (which_mutation == RANDOM_MUTATION\n",
      "        || which_mutation == RANDOM_XOM_MUTATION\n",
      "        || which_mutation == RANDOM_GOOD_MUTATION\n",
      "        || which_mutation == RANDOM_BAD_MUTATION\n",
      "        || which_mutation == RANDOM_NON_SLIME_MUTATION\n",
      "        || which_mutation == RANDOM_CORRUPT_MUTATION\n",
      "        || which_mutation == RANDOM_QAZLAL_MUTATION)\n",
      "    {\n",
      "        while (true)\n",
      "        {\n",
      "            if (one_chance_in(1000))\n",
      "                return false;\n",
      "\n",
      "            mutat = static_cast<mutation_type>(random2(NUM_MUTATIONS));\n",
      "\n",
      "            if (you.mutation[mutat] == 0\n",
      "                && mutat != MUT_STRONG\n",
      "                && mutat != MUT_CLEVER\n",
      "                && mutat != MUT_AGILE\n",
      "                && mutat != MUT_WEAK\n",
      "                && mutat != MUT_DOPEY\n",
      "                && mutat != MUT_CLUMSY)\n",
      "            {\n",
      "                continue;\n",
      "            }\n",
      "\n",
      "            if (which_mutation == RANDOM_NON_SLIME_MUTATION\n",
      "                && is_slime_mutation(mutat))\n",
      "            {\n",
      "                continue;\n",
      "            }\n",
      "\n",
      "            // Check whether there is a non-innate level of `mutat` to delete\n",
      "            if (you.get_base_mutation_level(mutat, false, true, true) == 0)\n",
      "                continue;\n",
      "\n",
      "            // MUT_ANTENNAE is 0, and you.attribute[] is initialized to 0.\n",
      "            if (mutat && mutat == you.attribute[ATTR_APPENDAGE])\n",
      "                continue;\n",
      "\n",
      "            const mutation_def& mdef = _get_mutation_def(mutat);\n",
      "\n",
      "            if (random2(10) >= mdef.weight && !is_slime_mutation(mutat))\n",
      "                continue;\n",
      "\n",
      "            const bool mismatch =\n",
      "                (which_mutation == RANDOM_GOOD_MUTATION\n",
      "                 && MUT_BAD(mdef))\n",
      "                    || (which_mutation == RANDOM_BAD_MUTATION\n",
      "                        && MUT_GOOD(mdef));\n",
      "\n",
      "            if (mismatch && (disallow_mismatch || !one_chance_in(10)))\n",
      "                continue;\n",
      "\n",
      "            if (you.get_base_mutation_level(mutat, true, false, true) == 0)\n",
      "                continue; // No non-transient mutations in this category to cure\n",
      "\n",
      "            break;\n",
      "        }\n",
      "    }\n",
      "    else if (which_mutation == RANDOM_SLIME_MUTATION)\n",
      "    {\n",
      "        mutat = _delete_random_slime_mutation();\n",
      "\n",
      "        if (mutat == NUM_MUTATIONS)\n",
      "            return false;\n",
      "    }\n",
      "\n",
      "    return _delete_single_mutation_level(mutat, reason, false); // won't delete temp mutations\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// ReadINode reads the inode from the symlink of form '<prefix>:[<inode>]' of the given path. If an error is encountered\n",
      "// or the inode symlink doesn't have the correct prefix, false is returned.\n",
      "bool ReadINode(int dirfd, const char* path, const char* prefix, ino_t* inode) {\n",
      "  char linkbuf[64];\n",
      "  ssize_t nread = readlinkat(dirfd, path, linkbuf, sizeof(linkbuf));\n",
      "  if (nread <= 0 || nread >= ssizeof(linkbuf) - 1) return false;\n",
      "  linkbuf[nread] = '\\0';\n",
      "  if (linkbuf[nread - 1] != ']') return false;\n",
      "\n",
      "  size_t prefix_len = std::strlen(prefix);\n",
      "  if (std::strncmp(linkbuf, prefix, prefix_len) != 0) return false;\n",
      "  if (std::strncmp(linkbuf + prefix_len, \":[\", 2) != 0) return false;\n",
      "\n",
      "  // Parse inode value as decimal\n",
      "  char* endp;\n",
      "  uintmax_t parsed = std::strtoumax(linkbuf + prefix_len + 2, &endp, 10);\n",
      "  if (*endp != ']') return false;\n",
      "  *inode = static_cast<ino_t>(parsed);\n",
      "  return true;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Converts a map of ObjectIdentifier counts to a string listing them.\n",
      "std::string TokenCountsToString(const std::map<ObjectIdentifier, int>& token_counts) {\n",
      "  std::ostringstream stream;\n",
      "  for (const auto& token : token_counts) {\n",
      "    stream << \"\\n\" << token.first << \" \" << token.second;\n",
      "  }\n",
      "  return stream.str();\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// returns number of characters correctly written, EXCLUDING null-terminator\n",
      "// events_string will contain the null-terminator if return value > 0.\n",
      "int EpollEventToString(const uint32_t event, char* const events_string, const size_t n) {\n",
      "    if (!(events_string && n)) return 0;\n",
      "\n",
      "#define DOALL(DOONE) \\\n",
      "    DOONE(IN)\\\n",
      "    DOONE(PRI)\\\n",
      "    DOONE(OUT)\\\n",
      "    DOONE(ERR)\\\n",
      "    DOONE(HUP)\\\n",
      "    DOONE(RDNORM)\\\n",
      "    DOONE(RDBAND)\\\n",
      "    DOONE(WRNORM)\\\n",
      "    DOONE(WRBAND)\\\n",
      "    DOONE(MSG)\\\n",
      "    DOONE(RDHUP)\\\n",
      "    DOONE(EXCLUSIVE)\\\n",
      "    DOONE(WAKEUP)\\\n",
      "    DOONE(ONESHOT)\\\n",
      "    DOONE(ET)\\\n",
      "\n",
      "#define EVENT_TO_STRING(x) \\\n",
      "    if (EPOLL##x == event) {\\\n",
      "        static const char s[] = #x;\\\n",
      "        const size_t num_bytes_to_write = sizeof(s);\\\n",
      "        if (n < num_bytes_to_write) return 0;\\\n",
      "        strncpy(events_string, s, num_bytes_to_write);\\\n",
      "        return num_bytes_to_write - 1;\\\n",
      "    }\n",
      "\n",
      "    DOALL(EVENT_TO_STRING)\n",
      "#undef EVENT_TO_STRING\n",
      "#undef DOALL\n",
      "\n",
      "    // snprintf returns the number of characters in the desired rendered string, EXCLUDING null-terminator.\n",
      "    // Therefore, string has been completely written only if returned value is positive and less than n.\n",
      "    const int e = snprintf(events_string, n, \"%x\", event);\n",
      "\n",
      "    return ((e > 0) && (static_cast<size_t>(e) < n)) ? e : 0;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "/// \\brief Entry point.\n",
      "///\n",
      "/// This is counterpart of ProduceBinaryInstructions from 'old' encoder\n",
      "void BinaryEncodingCNL::DoAll()\n",
      "{\n",
      "    std::vector<ForwardJmpOffset> offsetVector;\n",
      "    FixInst();\n",
      "    BinaryEncodingBase::InitPlatform();\n",
      "    // BDW/CHV/SKL/BXT/CNL use the same compaction tables except from 3src.\n",
      "    for (uint8_t i=0; i<(int)COMPACT_TABLE_SIZE; i++)\n",
      "    {\n",
      "        BDWCompactControlTable.AddIndex(IVBCompactControlTable[i], i);\n",
      "        BDWCompactSourceTable.AddIndex(IVBCompactSourceTable[i], i);\n",
      "        BDWCompactSubRegTable.AddIndex(IVBCompactSubRegTable[i], i);\n",
      "        BDWCompactSubRegTable.AddIndex1(IVBCompactSubRegTable[i] & 0x1F, i);\n",
      "        BDWCompactSubRegTable.AddIndex2(IVBCompactSubRegTable[i] & 0x3FF, i);\n",
      "        if (getGenxPlatform() >= GENX_ICLLP)\n",
      "        {\n",
      "            BDWCompactDataTypeTableStr.AddIndex(ICLCompactDataTypeTable[i], i);\n",
      "        }\n",
      "        else\n",
      "        {\n",
      "            BDWCompactDataTypeTableStr.AddIndex(BDWCompactDataTypeTable[i], i);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    int globalInstNum = 0;\n",
      "    int globalHalfInstNum = 0;\n",
      "    int numCompactedInst = 0;\n",
      "    int numCompacted3SrcInst = 0;\n",
      "\n",
      "    BB_LIST_ITER ib, bend(kernel.fg.end());\n",
      "    for (ib = kernel.fg.begin(); ib != bend; ++ib)\n",
      "    {\n",
      "        G4_BB *bb = *ib;\n",
      "        int localInstNum = 0;\n",
      "        int localHalfInstNum = 0;\n",
      "\n",
      "        /**\n",
      "         * Traverse the instruction lists\n",
      "         */\n",
      "        INST_LIST_ITER ii, iend(bb->end());\n",
      "        for (ii = bb->begin(); ii != iend; ++ii)\n",
      "        {\n",
      "            /* do detailed encoding here */\n",
      "            G4_INST *inst = *ii;\n",
      "            G4_opcode opcode = inst->opcode();\n",
      "\n",
      "            if (opcode == G4_label)\n",
      "            {\n",
      "                inst->setBinInst(NULL);\n",
      "            } else {\n",
      "                // reuse \"BinInst\" from BinaryEncoding.h which can be simplified\n",
      "                BinInst *bin = new (mem) BinInst();\n",
      "                inst->setBinInst(bin);\n",
      "\n",
      "                bin->DWords[0] = 0;\n",
      "                bin->DWords[1] = 0;\n",
      "                bin->DWords[2] = 0;\n",
      "                bin->DWords[3] = 0;\n",
      "\n",
      "                DoAllEncoding(inst);\n",
      "\n",
      "                if (inst->opcode() == G4_pseudo_fc_call ||\n",
      "                   inst->opcode() == G4_pseudo_fc_ret)\n",
      "                {\n",
      "                    inst->getBinInst()->SetDontCompactFlag(true);\n",
      "                }\n",
      "\n",
      "                if (doCompaction())\n",
      "                {\n",
      "                    inst->getBinInst()->SetMustCompactFlag(false);\n",
      "                    inst->getBinInst()->SetDontCompactFlag(inst->isNoCompactedInst());\n",
      "\n",
      "                    /**\n",
      "                     * handling switch/case for gen6: jump table should not be compacted\n",
      "                     */\n",
      "                    bool compacted;\n",
      "                    {\n",
      "                        TIME_SCOPE(ENCODE_COMPACTION);\n",
      "                        compacted = BinaryEncodingBase::compactOneInstruction(inst);\n",
      "                    }\n",
      "\n",
      "                    if (compacted)\n",
      "                    {\n",
      "                        if (kernel.getOption(vISA_OptReport))\n",
      "                        {\n",
      "                            numCompactedInst++;\n",
      "                            if (inst->getBinInst()->GetIs3Src())\n",
      "                                numCompacted3SrcInst++;\n",
      "                        }\n",
      "                        inst->setCompacted();\n",
      "                    }\n",
      "                }\n",
      "                binInstList.push_back(inst->getBinInst());\n",
      "\n",
      "                if (inst->opcode() >= G4_jmpi && inst->opcode() <= G4_join)\n",
      "                {\n",
      "                    if (!EncodeConditionalBranches(inst, globalHalfInstNum))\n",
      "                    {\n",
      "                        offsetVector.push_back(ForwardJmpOffset(inst, globalHalfInstNum));\n",
      "                    }\n",
      "                }\n",
      "            } //else\n",
      "\n",
      "            BuildLabelMap(inst, localHalfInstNum, localInstNum,\n",
      "                          globalHalfInstNum, globalInstNum);\n",
      "        } // for inst\n",
      "    } // for bb\n",
      "\n",
      "    kernel.setAsmCount(globalInstNum);\n",
      "    SetInstCounts((uint32_t)globalHalfInstNum);\n",
      "\n",
      "    EncodingHelper::dumpOptReport(globalInstNum, numCompactedInst, numCompacted3SrcInst, kernel);\n",
      "    for (auto x = offsetVector.begin(), vEnd = offsetVector.end(); x != vEnd; x++)\n",
      "    {\n",
      "        if (!EncodeConditionalBranches(x->inst, x->offset))\n",
      "        {\n",
      "            MUST_BE_TRUE(false, \"invalid label!\");\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Completed includes\n",
      "// Autogenerated instance field getter\n",
      "// Get instance field: public System.IDisposable Disposable\n",
      "System::IDisposable* Zenject::DisposableManager::DisposableInfo::_get_Disposable() {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"Zenject::DisposableManager::DisposableInfo::_get_Disposable\");\n",
      "  auto ___internal__instance = *this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"Disposable\"))->offset;\n",
      "  return *reinterpret_cast<System::IDisposable**>(reinterpret_cast<char*>(this) + ___internal__field__offset);\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// Autogenerated instance field setter\n",
      "// Set instance field: public System.Boolean advancedHud\n",
      "void GlobalNamespace::PlayerSaveDataV1_0_1::PlayerSpecificSettings::_set_advancedHud(bool value) {\n",
      "  static auto ___internal__logger = ::Logger::get().WithContext(\"GlobalNamespace::PlayerSaveDataV1_0_1::PlayerSpecificSettings::_set_advancedHud\");\n",
      "  auto ___internal__instance = this;\n",
      "  static auto ___internal__field__offset = THROW_UNLESS(il2cpp_utils::FindField(___internal__instance, \"advancedHud\"))->offset;\n",
      "  *reinterpret_cast<bool*>(reinterpret_cast<char*>(this) + ___internal__field__offset) = value;\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# self_training_sample = pd.read_excel('self_training_sample.xlsx')\n",
    "for sample in self_training_sample[self_training_sample.language=='C++'].iterrows():\n",
    "    print(sample[1]['original_docstring'])\n",
    "    print(sample[1]['original_string'])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8d9ab",
   "metadata": {},
   "source": [
    "Getting a random sample from the test split to test our baseline model. We will increase the size once we finalize the experimental plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae0f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = test_df.groupby('language', group_keys=False).sample(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026741f",
   "metadata": {},
   "source": [
    "# Testing the Baseline model\n",
    "\n",
    "Here we define the system prompt for the Llama 2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a303e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(language):\n",
    "    return \\\n",
    "f'''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "You will be provided with a block of {language} code and the existing doucmentation that accompanies it.\n",
    "Simplify the given documentation, using the provided code as context, so that it is understandable\n",
    "to beginner programmers. Output absolutely nothing else besides the simplified documentation.\n",
    "Make sure to keep any documentation formatting codes present in the simplified documentation.\n",
    "If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "it further, feel free to keep the documentation as is. Here is the original documentation and code:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b523e6",
   "metadata": {},
   "source": [
    "Creating the pipeline for the Llama 2 model using the HuggingFace transformers library. Modified from the example here: https://huggingface.co/docs/transformers/en/model_doc/llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa4efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ed2ba7a6dc414c9c2115ef815a01ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:3\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1bfaf",
   "metadata": {},
   "source": [
    "Testing the pipeline. Modified from examples given here: https://huggingface.co/docs/transformers/main/en/chat_templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6011ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Documentation:\n",
      "Build the library mappings tables.\n",
      "\n",
      "Code:\n",
      "def build_mapping_tables(app):\n",
      "    \"\"\"Build the library mappings tables.\"\"\"\n",
      "    env = Environment(loader=FileSystemLoader(f\"{DIR_PATH}\"))\n",
      "    template_file = env.get_template(\"table_template.j2\")\n",
      "\n",
      "    LIST_OF_MAP_DICTS = []\n",
      "    for attr in dir(lib_mapper):\n",
      "        if (attr.endswith(\"MAPPER_REVERSE\") or attr.endswith(\"_MAPPER\")) and not (\n",
      "            attr.startswith(\"_\") or attr.startswith(\"NETMIKO\") or attr.startswith(\"MAIN\")\n",
      "        ):\n",
      "            LIST_OF_MAP_DICTS.append(attr)\n",
      "\n",
      "    for dict_name in LIST_OF_MAP_DICTS:\n",
      "        lib_name = dict_name.split(\"_\")[0]\n",
      "        filename = f\"{lib_name}_reverse\" if \"REVERSE\" in dict_name else lib_name\n",
      "        headers = [\"NORMALIZED\", lib_name] if \"REVERSE\" in dict_name else [lib_name, \"NORMALIZED\"]\n",
      "        rendered_template = template_file.render(lib_names=headers, mappings=getattr(lib_mapper, dict_name))\n",
      "        with open(f\"{DIR_PATH}/netutils/lib_mapping/{filename}_table.rst\", \"w\") as table_file:\n",
      "            table_file.write(rendered_template)\n",
      "\n",
      "  Simplified documentation:\n",
      "\n",
      "Build the library mappings tables.\n",
      "\n",
      "This function builds the tables that map the names of libraries in the `netutils` package to their corresponding reverse names. It does this by iterating through the directories in the `netutils` package, and for each directory, it renders a template file that defines the mappings. The template file is rendered with the help of the `getattr` function, which retrieves the mappings for the current library name from the `lib_mapper` module.\n",
      "\n",
      "The function first imports the `Environment` class from the `j2` package, which is used to load the template file. It then defines a list of dicts (`LIST_OF_MAP_DICTS`) that contains the names of the libraries that have mappings.\n",
      "\n",
      "The function then iterates through the list of dicts and builds the mappings table for each library. For each library, it defines the headers of the table, which are the normalized name of the library and the original name of the library. It then renders the template file using the `render` method, and writes the rendered file to the `netutils/lib_mapping` directory.\n",
      "\n",
      "Note: The `DIR_PATH` variable is not defined in the code snippet provided, so you will need to replace it with the actual directory path where the `netutils` package is located.\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    {\"role\": \"system\", \"content\": prompt(dataset['test'][0]['language'])},\n",
    "    {\"role\": \"user\", \"content\": f\"Documentation:\\n{dataset['test'][0]['original_docstring']}\\n\\nCode:\\n{dataset['test'][0]['original_string']}\"}\n",
    "]\n",
    "print(f\"Original Documentation:\\n{dataset['test'][0]['original_docstring']}\\n\")\n",
    "print(f\"Code:\\n{dataset['test'][0]['original_string']}\\n\")\n",
    "print(pipe(message, pad_token_id=pipe.tokenizer.eos_token_id)[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da96447",
   "metadata": {},
   "source": [
    "Loading the evaluation model used for computing semantic similarity. Taken from example here: https://huggingface.co/tasks/sentence-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf2e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2f233",
   "metadata": {},
   "source": [
    "Running inference on the dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b05b3770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/j/jwoods03/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "9it [01:30, 11.89s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "200it [24:58,  7.49s/it]\n"
     ]
    }
   ],
   "source": [
    "semantic_similarities = []\n",
    "metrics = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "for instance in tqdm(dataset_sample.itertuples()):\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": prompt(instance.language)},\n",
    "        {\"role\": \"user\", \"content\": f\"Documentation:\\n{instance.original_docstring}\\n\\nCode:\\n{instance.original_string}\"}\n",
    "    ]\n",
    "\n",
    "    result = pipe(message, pad_token_id=pipe.tokenizer.eos_token_id)[0]['generated_text'][-1]['content']\n",
    "\n",
    "    embedding_original = eval_model.encode(instance.original_docstring, convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    semantic_similarities.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    metrics.add(predictions=result, references=instance.original_docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d144bea",
   "metadata": {},
   "source": [
    "Summary statistics for semantic similarity results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e295fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.649289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.161408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.161233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.553146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.665742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.775409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.967906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.649289\n",
       "std      0.161408\n",
       "min      0.161233\n",
       "25%      0.553146\n",
       "50%      0.665742\n",
       "75%      0.775409\n",
       "max      0.967906"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(semantic_similarities).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07954701",
   "metadata": {},
   "source": [
    "ROUGE and METEOR results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b08bf030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.23746285790317642,\n",
       " 'rouge2': 0.15850905081486888,\n",
       " 'rougeL': 0.20873611382827575,\n",
       " 'rougeLsum': 0.23081417919447733,\n",
       " 'meteor': 0.35096813813331496}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis532",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
