{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7063800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eebc4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35485c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30c7aafd11f41afa51486dd71f0ea82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset = load_dataset('code-search-net/code_search_net')\n",
    "dataset = load_dataset(\"Fsoft-AIC/the-vault-function\", split_set=[\"test\"], trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcca6194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hexsha', 'repo', 'path', 'license', 'language', 'identifier',\n",
       "       'return_type', 'original_string', 'original_docstring', 'docstring',\n",
       "       'docstring_tokens', 'code', 'code_tokens', 'short_docstring',\n",
       "       'short_docstring_tokens', 'comment', 'parameters', 'docstring_params'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.DataFrame(dataset['test'])\n",
    "sample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759c19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hexsha', 'repo', 'path', 'license', 'language', 'identifier',\n",
       "       'return_type', 'original_string', 'original_docstring', 'docstring',\n",
       "       'docstring_tokens', 'code', 'code_tokens', 'short_docstring',\n",
       "       'short_docstring_tokens', 'comment', 'parameters', 'docstring_params'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample = sample_df.groupby('language', group_keys=False).sample(n=20)\n",
    "dataset_sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75727e7",
   "metadata": {},
   "source": [
    "# Testing the Baseline model\n",
    "\n",
    "Here we define the system prompt for the Llama 2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa72c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prompt(language, documentation, code):\n",
    "    return \\\n",
    "    f'''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "    You will be provided with a block of {language} code and the existing doucmentation that accompanies it.\n",
    "    Simplify the given documentation, using the provided code as context, so that it is understandable\n",
    "    to beginner programmers. Output absolutely nothing else besides the simplified documentation.\n",
    "    Make sure to keep any documentation formatting codes present in the simplified documentation.\n",
    "    If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "    it further, feel free to keep the documentation as is. Here is the original documentation and code:\\n\n",
    "    Documentation:\\n{documentation}\\n\\nCode:\\n{code}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "985d1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_prompt(language, comment, code):\n",
    "    prompt_gemma = \\\n",
    "    '''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "    You will be provided with a block of {LANGUAGE} code and the existing doucmentation that accompanies it.\n",
    "    Using the provided code as context, give a simplified explanation of the code so that it is understandable\n",
    "    to beginner programmers. Output absolutely nothing else besides the simplified explanation.\n",
    "    Make sure to keep any documentation formatting codes present in the simplified explanation.\n",
    "    If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "    it further, feel free to keep the documentation as is. Here is the original documentation and code: \\nDocumenation:\\n{Documentation}\\n\\nCode:\\n{CODE}'''.format(LANGUAGE=language, Documentation=comment, CODE=code)\n",
    "    \n",
    "    return prompt_gemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd58925",
   "metadata": {},
   "source": [
    "Creating the pipeline for the Gemma 3 model using the HuggingFace transformers library. Modified from the example here: https://huggingface.co/docs/transformers/v4.51.3/en/model_doc/gemma#gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5bbc1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f979eb42f3e42deb2ad4249597a829b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0add8886f654941a3fc1d7549313bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb3eb59bf7d485e9d89f37b8d5033d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b792c666723b4be799424cc13fe5309f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b808c42a0f44b28933d7e6de3592f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f90523c5a04f09b9b004246c9c4f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c33281e67b5478eada80881c01923b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3e37638fd64af69b289d454b1d0f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82158f00a41f44eb85e63d0ddcb41615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af7cbcb129e4b5e8909f24d55f71e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1987bde0d83b4cccbf4addd411b1e35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691c791a2ede4c70bd30af222743bf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "The model 'Gemma3ForConditionalGeneration' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pipe_gemma = pipeline(\\n    \"text2text-generation\",\\n    model=\"google/gemma-3-4b-it\",\\n    torch_dtype=torch.float32,\\n    device=\"cpu\"\\n)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_gemma = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    torch_dtype=torch.float32,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\"\"\"pipe_gemma = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    torch_dtype=torch.float32,\n",
    "    device=\"cpu\"\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee38e16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8075e97b49a14f15b9f7862c9fb43525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0561d78abd9d47399da7fcb6dae926bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289fc1ff1dc2437abb701687532f61b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69aab213cd2d429d8aa5568b128dbce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05576c61f4dd4505a53820de74b7c09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c30065966e4fca9d25403d2b84fc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4a920f02484769b84911270540a51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c71737f53ab401f9aabff3ea49a72ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611ebfacfe3344e5b63767686514bca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6a0d7fb332451f98d41b91313eb698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ec50e27a4f4827a734cb92d835de7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65530953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Documentation:\n",
      "Build the library mappings tables.\n",
      "\n",
      "Code:\n",
      "def build_mapping_tables(app):\n",
      "    \"\"\"Build the library mappings tables.\"\"\"\n",
      "    env = Environment(loader=FileSystemLoader(f\"{DIR_PATH}\"))\n",
      "    template_file = env.get_template(\"table_template.j2\")\n",
      "\n",
      "    LIST_OF_MAP_DICTS = []\n",
      "    for attr in dir(lib_mapper):\n",
      "        if (attr.endswith(\"MAPPER_REVERSE\") or attr.endswith(\"_MAPPER\")) and not (\n",
      "            attr.startswith(\"_\") or attr.startswith(\"NETMIKO\") or attr.startswith(\"MAIN\")\n",
      "        ):\n",
      "            LIST_OF_MAP_DICTS.append(attr)\n",
      "\n",
      "    for dict_name in LIST_OF_MAP_DICTS:\n",
      "        lib_name = dict_name.split(\"_\")[0]\n",
      "        filename = f\"{lib_name}_reverse\" if \"REVERSE\" in dict_name else lib_name\n",
      "        headers = [\"NORMALIZED\", lib_name] if \"REVERSE\" in dict_name else [lib_name, \"NORMALIZED\"]\n",
      "        rendered_template = template_file.render(lib_names=headers, mappings=getattr(lib_mapper, dict_name))\n",
      "        with open(f\"{DIR_PATH}/netutils/lib_mapping/{filename}_table.rst\", \"w\") as table_file:\n",
      "            table_file.write(rendered_template)\n",
      "\n",
      "***********************Result************************************\n",
      "You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
      "    You will be provided with a block of Python code and the existing doucmentation that accompanies it.\n",
      "    Using the provided code as context, give a simplified explanation of the code so that it is understandable\n",
      "    to beginner programmers. Output absolutely nothing else besides the simplified explanation.\n",
      "    Make sure to keep any documentation formatting codes present in the simplified explanation.\n",
      "    If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
      "    it further, feel free to keep the documentation as is. Here is the original documentation and code: \n",
      "Documenation:\n",
      "Build the library mappings tables.\n",
      "\n",
      "Code:\n",
      "def build_mapping_tables(app):\n",
      "    \"\"\"Build the library mappings tables.\"\"\"\n",
      "    env = Environment(loader=FileSystemLoader(f\"{DIR_PATH}\"))\n",
      "    template_file = env.get_template(\"table_template.j2\")\n",
      "\n",
      "    LIST_OF_MAP_DICTS = []\n",
      "    for attr in dir(lib_mapper):\n",
      "        if (attr.endswith(\"MAPPER_REVERSE\") or attr.endswith(\"_MAPPER\")) and not (\n",
      "            attr.startswith(\"_\") or attr.startswith(\"NETMIKO\") or attr.startswith(\"MAIN\")\n",
      "        ):\n",
      "            LIST_OF_MAP_DICTS.append(attr)\n",
      "\n",
      "    for dict_name in LIST_OF_MAP_DICTS:\n",
      "        lib_name = dict_name.split(\"_\")[0]\n",
      "        filename = f\"{lib_name}_reverse\" if \"REVERSE\" in dict_name else lib_name\n",
      "        headers = [\"NORMALIZED\", lib_name] if \"REVERSE\" in dict_name else [lib_name, \"NORMALIZED\"]\n",
      "        rendered_template = template_file.render(lib_names=headers, mappings=getattr(lib_mapper, dict_name))\n",
      "        with open(f\"{DIR_PATH}/netutils/lib_mapping/{filename}_table.rst\", \"w\") as table_file:\n",
      "            table_file.write(rendered_template)\n",
      "\n",
      "Here is a simplified explanation of the code:\n",
      "This code creates tables that map different libraries to their corresponding data. It does this by:\n",
      "1.  Loading a template file that defines the structure of the tables.\n",
      "2.  Finding specific attributes within a library object (called `lib_mapper`) that relate to these mappings.\n",
      "3.  For each of these attributes, it creates a table file with the appropriate name and content.\n",
      "    The table content is generated using the template and the library name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"message = [[\n",
    "    {\"role\": \"system\", \"content\": prompt(dataset['test'][0]['language'])},\n",
    "    {\"role\": \"user\", \"content\": f\"Documentation:\\n{dataset['test'][0]['original_docstring']}\\n\\nCode:\\n{dataset['test'][0]['original_string']}\"}\n",
    "]]\"\"\"\n",
    "lan = dataset['test'][0]['language']\n",
    "code = dataset['test'][0]['original_string']\n",
    "doc = dataset['test'][0]['original_docstring']\n",
    "print(f\"Original Documentation:\\n{dataset['test'][0]['original_docstring']}\\n\")\n",
    "print(f\"Code:\\n{dataset['test'][0]['original_string']}\\n\")\n",
    "print(\"***********************Result************************************\")\n",
    "print(pipe_gemma(llm_prompt(lan, doc, code), pad_token_id=pipe_gemma.tokenizer.eos_token_id, max_new_tokens=150)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c386b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b06372ffca144ef8d83547d4f37e808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0d39a23a4e4f4dabaa69ae78aeb397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/adeniji/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/adeniji/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /home/adeniji/nltk_data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8246ecbfb944189f0917b9c0e64ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "generated_documents = []\n",
    "gemma_semantic_similarities_untrained = []\n",
    "gemma_metrics_untrained = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "for instance in tqdm(dataset_sample.itertuples()):\n",
    "    lan = instance.language\n",
    "    code = instance.original_docstring\n",
    "    doc = instance.original_string\n",
    "\n",
    "    message = llm_prompt(lan, doc, code)\n",
    "\n",
    "    result = pipe_gemma(message, pad_token_id=pipe_gemma.tokenizer.eos_token_id, max_new_tokens=150)[0]['generated_text']\n",
    "\n",
    "    generated_documents.append(result)\n",
    "    #result = output.replace(message, \"\")\n",
    "\n",
    "    embedding_original = eval_model.encode(instance.original_docstring, convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    gemma_semantic_similarities_untrained.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    gemma_metrics_untrained.add(predictions=result, references=instance.original_docstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06e1a5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained Gemma 3: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.491806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.135416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.043898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.397880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.504949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.584478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.816752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.491806\n",
       "std      0.135416\n",
       "min      0.043898\n",
       "25%      0.397880\n",
       "50%      0.504949\n",
       "75%      0.584478\n",
       "max      0.816752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Untrained Gemma 3: \\n\")\n",
    "sims_untrianed = pd.DataFrame(gemma_semantic_similarities_untrained)\n",
    "sims_untrianed.to_excel('results/Semantic_Similarities_Gemma_untrained.xlsx')\n",
    "sims_untrianed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07e6f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results/rouge_meteor_gemma_untrained.json', 'w') as file:\n",
    "    mr = gemma_metrics_untrained.compute()\n",
    "    json.dump(mr, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_generations = pd.DataFrame(generated_documents)\n",
    "untrained_generations.to_excel('resulsts/gemma_3_untriained_generated_documents.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations_df = pd.read_excel('resulsts/gemma_3_untriained_generated_documents.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66620ff",
   "metadata": {},
   "source": [
    "# Testing the FineTuned model\n",
    "\n",
    "Here we Import the training examples from an excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89fe1a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'original_string', 'original_docstring',\n",
       "       'modified_short_docstring'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_excel(\"self_training_annotated.xlsx\", sheet_name=\"Sheet1\", usecols=[5, 8, 9, 16])\n",
    "training_sample = train_df.groupby('language', group_keys=False).sample(n=5)\n",
    "training_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1847f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_prompt(language, documentation, code, modified):\n",
    "    return \\\n",
    "    f'''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "    You will be provided with a block of {language} code and the existing doucmentation that accompanies it.\n",
    "    Simplify the given documentation, using the provided code as context, so that it is understandable\n",
    "    to beginner programmers. Output absolutely nothing else besides the simplified documentation.\n",
    "    Make sure to keep any documentation formatting codes present in the simplified documentation.\n",
    "    If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "    it further, feel free to keep the documentation as is. Here is the original documentation and code:\\n\n",
    "    Code:\\n{code}\\n\\nDocumentation:\\n{documentation}\\n\\nModified documentation:\\n{modified}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4fac96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed136ffddaf74deaa12ed3a5866a9369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for instance in tqdm(training_sample.itertuples()):\n",
    "    lan = instance.language\n",
    "    code = instance.original_docstring\n",
    "    doc = instance.original_string\n",
    "    mod = instance.modified_short_docstring\n",
    "\n",
    "    message = training_prompt(lan, doc, code, mod)\n",
    "\n",
    "    pipe_gemma(message, pad_token_id=pipe_gemma.tokenizer.eos_token_id, max_new_tokens=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36182a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983af1b8462743cfa4a481d1058cded3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_semantic_similarities_trained = []\n",
    "gemma_metrics_trained = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "\n",
    "for instance in tqdm(dataset_sample.itertuples()):\n",
    "    lan = instance.language\n",
    "    code = instance.original_docstring\n",
    "    doc = instance.original_string\n",
    "\n",
    "    message = test_prompt(lan, doc, code)\n",
    "\n",
    "    result = pipe_gemma(message, pad_token_id=pipe_gemma.tokenizer.eos_token_id, max_new_tokens=30)[0]['generated_text']\n",
    "\n",
    "    embedding_original = eval_model.encode(instance.original_docstring, convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    gemma_semantic_similarities_trained.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    gemma_metrics_trained.add(predictions=result, references=instance.original_docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80efc66",
   "metadata": {},
   "source": [
    "# Summary statistics results\n",
    "Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd2ad74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Gemma 3: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.504685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.141379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.051231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.409741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.516998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.609724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.840501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.504685\n",
       "std      0.141379\n",
       "min      0.051231\n",
       "25%      0.409741\n",
       "50%      0.516998\n",
       "75%      0.609724\n",
       "max      0.840501"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Trained Gemma 3: \\n\")\n",
    "sims_trained = pd.DataFrame(gemma_semantic_similarities_trained)\n",
    "sims_trained.to_excel('results/Semantic_Similarities_Gemma_trained.xlsx')\n",
    "sims_trained.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132c1db",
   "metadata": {},
   "source": [
    "ROUGE AND METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae45fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/rouge_meteor_gemma_trained.json', 'w') as file:\n",
    "    mr = gemma_metrics_trained.compute()\n",
    "    json.dump(mr, file, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis732",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
