{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7063800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eebc4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35485c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35c40438c874ef98d58eb780345fc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/11.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375563b0b33a48f8b97d12dd338e4f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "the-vault-function.py:   0%|          | 0.00/15.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f057617ab22c43f2b09e974a97f46ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "python-00000-of-00001.parquet:   0%|          | 0.00/30.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c5a548ef164ece8faf7d36231d4708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "c-00000-of-00001.parquet:   0%|          | 0.00/25.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915a8174dbd045a891fdb0d63987665a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "c_sharp-00000-of-00001.parquet:   0%|          | 0.00/18.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3062612bdb34ab6b5648c7b10b39b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cpp-00000-of-00001.parquet:   0%|          | 0.00/23.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098f0f6a2b35495bba43ae77bbefde89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "go-00000-of-00001.parquet:   0%|          | 0.00/19.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5778ba473c044377b787a2eed3a13a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "java-00000-of-00001.parquet:   0%|          | 0.00/19.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7f36fc871d403fae2ce8a3cc98422a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "javascript-00000-of-00001.parquet:   0%|          | 0.00/26.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d594a391049e439faefd271614ea3345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "php-00000-of-00001.parquet:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20a8d33209c4c6fbabf5163f5a0e82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ruby-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c25e6480e44e98aa20bff79d84b61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rust-00000-of-00001.parquet:   0%|          | 0.00/29.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51183c6dade949b7a644eb4f7d5bc49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset = load_dataset('code-search-net/code_search_net')\n",
    "dataset = load_dataset(\"Fsoft-AIC/the-vault-function\", split_set=[\"test\"], trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcca6194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hexsha', 'repo', 'path', 'license', 'language', 'identifier',\n",
       "       'return_type', 'original_string', 'original_docstring', 'docstring',\n",
       "       'docstring_tokens', 'code', 'code_tokens', 'short_docstring',\n",
       "       'short_docstring_tokens', 'comment', 'parameters', 'docstring_params'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.DataFrame(dataset['test'])\n",
    "sample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759c19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hexsha', 'repo', 'path', 'license', 'language', 'identifier',\n",
       "       'return_type', 'original_string', 'original_docstring', 'docstring',\n",
       "       'docstring_tokens', 'code', 'code_tokens', 'short_docstring',\n",
       "       'short_docstring_tokens', 'comment', 'parameters', 'docstring_params'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample = sample_df.groupby('language', group_keys=False).sample(n=20)\n",
    "dataset_sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75727e7",
   "metadata": {},
   "source": [
    "# Testing the Baseline model\n",
    "\n",
    "Here we define the system prompt for the Llama 2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985d1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_prompt(language, comment, code):\n",
    "    prompt_gemma = \\\n",
    "    '''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "    You will be provided with a block of {LANGUAGE} code and the existing doucmentation that accompanies it.\n",
    "    Using the provided code as context, give a simplified explanation of the code so that it is understandable\n",
    "    to beginner programmers. Output absolutely nothing else besides the simplified explanation.\n",
    "    Make sure to keep any documentation formatting codes present in the simplified explanation.\n",
    "    If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "    it further, feel free to keep the documentation as is. Here is the original documentation and code: \\nDocumenation:\\n{Documentation}\\n\\nCode:\\n{CODE}'''.format(LANGUAGE=language, Documentation=comment, CODE=code)\n",
    "    \n",
    "    return prompt_gemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd58925",
   "metadata": {},
   "source": [
    "Creating the pipeline for the Gemma 3 model using the HuggingFace transformers library. Modified from the example here: https://huggingface.co/docs/transformers/v4.51.3/en/model_doc/gemma#gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5bbc1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c83b1fb86bd4fb49864aa869145f286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b98db724edc4c2592eb366e4dc68bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb97895806547f6aa7a10c5f0f69709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aaf55a767a447d90b08cf6ef87ecfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb21b2cd38d4f8fbc0b2ce6ed0ba9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bcf5f3fec24b129dad2b78a132d61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdd6452b22944d09f48f6a0fcd7ace0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9e9ce2957045878a781e80cebf5617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d01e8ad3784b76a52fdf7ebdc21e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65114af5837f484f878cf1ec48bd8566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b6b2ee3b0e4bdb8cca508fc19d9bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971a96e8d5d343e6ad8113303192eada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "The model 'Gemma3ForConditionalGeneration' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pipe_gemma = pipeline(\\n    \"text2text-generation\",\\n    model=\"google/gemma-3-4b-it\",\\n    torch_dtype=torch.float32,\\n    device=\"cpu\"\\n)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_gemma = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    torch_dtype=torch.float32,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\"\"\"pipe_gemma = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    torch_dtype=torch.float32,\n",
    "    device=\"cpu\"\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee38e16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affa60ea8a97469dad32aeafdb7c7e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15df86f44822436ab1e16617d91cebbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e722d833404ac8b52b03d9c2a1f02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8b6423a25d40538689ac4995375e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4052ef8e944fcbad5bc9ddc4d207d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0011fce745d24e46a5b7dd783b2aa245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24173a8f2bc4a6ba6e170ee5b79f6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016c659d3ead4320a30f252c6f0d7710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6399308b374f03842d3c212a8ff2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8e1e89f85d460c98d1acff8cc78bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ba43c3b28449e0bac76e8c9a379181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65530953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Documentation:\n",
      "Build the library mappings tables.\n",
      "\n",
      "Code:\n",
      "def build_mapping_tables(app):\n",
      "    \"\"\"Build the library mappings tables.\"\"\"\n",
      "    env = Environment(loader=FileSystemLoader(f\"{DIR_PATH}\"))\n",
      "    template_file = env.get_template(\"table_template.j2\")\n",
      "\n",
      "    LIST_OF_MAP_DICTS = []\n",
      "    for attr in dir(lib_mapper):\n",
      "        if (attr.endswith(\"MAPPER_REVERSE\") or attr.endswith(\"_MAPPER\")) and not (\n",
      "            attr.startswith(\"_\") or attr.startswith(\"NETMIKO\") or attr.startswith(\"MAIN\")\n",
      "        ):\n",
      "            LIST_OF_MAP_DICTS.append(attr)\n",
      "\n",
      "    for dict_name in LIST_OF_MAP_DICTS:\n",
      "        lib_name = dict_name.split(\"_\")[0]\n",
      "        filename = f\"{lib_name}_reverse\" if \"REVERSE\" in dict_name else lib_name\n",
      "        headers = [\"NORMALIZED\", lib_name] if \"REVERSE\" in dict_name else [lib_name, \"NORMALIZED\"]\n",
      "        rendered_template = template_file.render(lib_names=headers, mappings=getattr(lib_mapper, dict_name))\n",
      "        with open(f\"{DIR_PATH}/netutils/lib_mapping/{filename}_table.rst\", \"w\") as table_file:\n",
      "            table_file.write(rendered_template)\n",
      "\n",
      "***********************Result************************************\n",
      "You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
      "    You will be provided with a block of Python code and the existing doucmentation that accompanies it.\n",
      "    Using the provided code as context, give a simplified explanation of the code so that it is understandable\n",
      "    to beginner programmers. Output absolutely nothing else besides the simplified explanation.\n",
      "    Make sure to keep any documentation formatting codes present in the simplified explanation.\n",
      "    If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
      "    it further, feel free to keep the documentation as is. Here is the original documentation and code: \n",
      "Documenation:\n",
      "Build the library mappings tables.\n",
      "\n",
      "Code:\n",
      "def build_mapping_tables(app):\n",
      "    \"\"\"Build the library mappings tables.\"\"\"\n",
      "    env = Environment(loader=FileSystemLoader(f\"{DIR_PATH}\"))\n",
      "    template_file = env.get_template(\"table_template.j2\")\n",
      "\n",
      "    LIST_OF_MAP_DICTS = []\n",
      "    for attr in dir(lib_mapper):\n",
      "        if (attr.endswith(\"MAPPER_REVERSE\") or attr.endswith(\"_MAPPER\")) and not (\n",
      "            attr.startswith(\"_\") or attr.startswith(\"NETMIKO\") or attr.startswith(\"MAIN\")\n",
      "        ):\n",
      "            LIST_OF_MAP_DICTS.append(attr)\n",
      "\n",
      "    for dict_name in LIST_OF_MAP_DICTS:\n",
      "        lib_name = dict_name.split(\"_\")[0]\n",
      "        filename = f\"{lib_name}_reverse\" if \"REVERSE\" in dict_name else lib_name\n",
      "        headers = [\"NORMALIZED\", lib_name] if \"REVERSE\" in dict_name else [lib_name, \"NORMALIZED\"]\n",
      "        rendered_template = template_file.render(lib_names=headers, mappings=getattr(lib_mapper, dict_name))\n",
      "        with open(f\"{DIR_PATH}/netutils/lib_mapping/{filename}_table.rst\", \"w\") as table_file:\n",
      "            table_file.write(rendered_template)\n",
      "    \n",
      "    return LIST_OF_MAP_DICTS\n",
      "Here is a simplified explanation:\n",
      "This code creates tables that map values from a library to other values.\n",
      "Specifically, it looks for attributes in a library object called `lib_mapper` that have names like \"MAPPER_REVERSE\" or \"_MAPPER\".\n",
      "It then uses these names to create table files that describe the mappings.\n",
      "The code uses a template to format the tables in a specific way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lan = dataset['test'][0]['language']\n",
    "code = dataset['test'][0]['original_string']\n",
    "doc = dataset['test'][0]['original_docstring']\n",
    "print(f\"Original Documentation:\\n{dataset['test'][0]['original_docstring']}\\n\")\n",
    "print(f\"Code:\\n{dataset['test'][0]['original_string']}\\n\")\n",
    "print(\"***********************Result************************************\")\n",
    "print(pipe_gemma(llm_prompt(lan, doc, code), pad_token_id=pipe_gemma.tokenizer.eos_token_id, max_new_tokens=150)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c386b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468c256bb6104bad9a077c20e14ce6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_documents = []\n",
    "gemma_semantic_similarities_untrained = []\n",
    "gemma_metrics_untrained = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "for instance in tqdm(dataset_sample.itertuples()):\n",
    "    language = instance.language\n",
    "    original_doc = instance.original_docstring\n",
    "    orignal_code = instance.original_string\n",
    "\n",
    "    message = llm_prompt(language, original_doc, orignal_code)\n",
    "\n",
    "    result = pipe_gemma(message, pad_token_id=pipe_gemma.tokenizer.eos_token_id, max_new_tokens=150)[0]['generated_text']\n",
    "\n",
    "    result = result.replace(message, \"\")\n",
    "\n",
    "    embedding_original = eval_model.encode(instance.original_docstring, convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    gemma_semantic_similarities_untrained.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    gemma_metrics_untrained.add(predictions=result, references=instance.original_docstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06e1a5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained Gemma 3: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.588644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.214955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.035175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.497760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.633050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.726025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.588644\n",
       "std      0.214955\n",
       "min     -0.035175\n",
       "25%      0.497760\n",
       "50%      0.633050\n",
       "75%      0.726025\n",
       "max      1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Untrained Gemma 3: \\n\")\n",
    "sims_untrianed = pd.DataFrame(gemma_semantic_similarities_untrained)\n",
    "sims_untrianed.to_excel('results/Semantic_Similarities_Gemma_untrained.xlsx')\n",
    "sims_untrianed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07e6f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results/rouge_meteor_gemma_untrained.json', 'w') as file:\n",
    "    mr = gemma_metrics_untrained.compute()\n",
    "    json.dump(mr, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66620ff",
   "metadata": {},
   "source": [
    "# Testing the FineTuned model\n",
    "\n",
    "Here we Import the training examples from an excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89fe1a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'original_string', 'original_docstring',\n",
       "       'modified_short_docstring'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_excel(\"self_training_annotated.xlsx\", sheet_name=\"Sheet1\", usecols=[5, 8, 9, 16])\n",
    "training_sample = train_df.groupby('language', group_keys=False).sample(n=5)\n",
    "training_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1847f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_prompt(language, documentation, code, modified):\n",
    "    prompt_gemma = \\\n",
    "    '''You are a helpful agent designed to help beginner programmers learn the fundamentals of programming.\n",
    "    You will be provided with a block of {LANGUAGE} code and the existing doucmentation that accompanies it.\n",
    "    You will also be provided a simplified version of the documentation. Using the provided code as context,\n",
    "    your goal is to understand how the documentation is simplified while being contextually relevant to the \n",
    "    original code. Output absolutely nothing. If you feel that the simplified documentation is simple and contextually \n",
    "    relevant learn from the example. If you do feel  the simplified documentaiton is not simple or not contextually relevant\n",
    "    forget about the example. Here is the original documentation and code:\\n \n",
    "    Code:\\n{CODE}\\n\\nDocumentation:\\n{DOCUMENTATION}\\n\\nModified documentation:\\n{MODIFIED}'''.format(LANGUAGE=language, DOCUMENTATION=documentation, CODE=code, MODIFIED=modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4fac96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed136ffddaf74deaa12ed3a5866a9369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for instance in tqdm(training_sample.itertuples()):\n",
    "    language = instance.language\n",
    "    original_doc = instance.original_docstring\n",
    "    orignal_code = instance.original_string\n",
    "    mod = instance.modified_short_docstring\n",
    "\n",
    "    message = training_prompt(language, original_doc, orignal_code, mod)\n",
    "\n",
    "    pipe_gemma(message, pad_token_id=pipe_gemma.tokenizer.eos_token_id, max_new_tokens=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36182a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983af1b8462743cfa4a481d1058cded3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_semantic_similarities_trained = []\n",
    "gemma_metrics_trained = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "\n",
    "for instance in tqdm(dataset_sample.itertuples()):\n",
    "    language = instance.language\n",
    "    original_doc = instance.original_docstring\n",
    "    orignal_code = instance.original_string\n",
    "\n",
    "    message = llm_prompt(language, original_doc, orignal_code)\n",
    "\n",
    "    result = pipe_gemma(message, pad_token_id=pipe_gemma.tokenizer.eos_token_id, max_new_tokens=30)[0]['generated_text']\n",
    "\n",
    "    embedding_original = eval_model.encode(instance.original_docstring, convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    gemma_semantic_similarities_trained.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    gemma_metrics_trained.add(predictions=result, references=instance.original_docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80efc66",
   "metadata": {},
   "source": [
    "# Summary statistics results\n",
    "Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd2ad74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Gemma 3: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.504685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.141379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.051231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.409741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.516998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.609724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.840501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  200.000000\n",
       "mean     0.504685\n",
       "std      0.141379\n",
       "min      0.051231\n",
       "25%      0.409741\n",
       "50%      0.516998\n",
       "75%      0.609724\n",
       "max      0.840501"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Trained Gemma 3: \\n\")\n",
    "sims_trained = pd.DataFrame(gemma_semantic_similarities_trained)\n",
    "sims_trained.to_excel('results/Semantic_Similarities_Gemma_trained.xlsx')\n",
    "sims_trained.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132c1db",
   "metadata": {},
   "source": [
    "ROUGE AND METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae45fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/rouge_meteor_gemma_trained.json', 'w') as file:\n",
    "    mr = gemma_metrics_trained.compute()\n",
    "    json.dump(mr, file, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis732",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
