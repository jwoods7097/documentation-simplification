{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7063800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eebc4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35485c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dea5fe3617d4f61a0af3141e4596125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ff60a1352943d18c71e3fd84fa5fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "code_search_net.py:   0%|          | 0.00/8.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3084baa67fdd4e25a8babee6039c481a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "python.zip:   0%|          | 0.00/941M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583e01e478504d2fba398bff6c79958c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "java.zip:   0%|          | 0.00/1.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1eabf38e93422e8df50c631dc78011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "javascript.zip:   0%|          | 0.00/1.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0374a1c83e4ae6802801e06dbe1591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "go.zip:   0%|          | 0.00/488M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48dc727cb7e74ace8ec59cb2e3629014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ruby.zip:   0%|          | 0.00/112M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a4cd22a2424ac5bd13dbccb1b045ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "php.zip:   0%|          | 0.00/852M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb46ecca05245ec95808a0bc6efef49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1880853 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e358ae4424634cab94b8e9dc93051ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a211c93c2ac741ebb647f373bea4bcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/89154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('code-search-net/code_search_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcca6194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repository_name', 'func_path_in_repository', 'func_name',\n",
       "       'whole_func_string', 'language', 'func_code_string', 'func_code_tokens',\n",
       "       'func_documentation_string', 'func_documentation_tokens', 'split_name',\n",
       "       'func_code_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.DataFrame(dataset['train'])\n",
    "sample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d636f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'docstring', 'code', 'short_docstring'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_excel(\"self_training_sample_Fsoft.xlsx\", sheet_name=\"Sheet2\", usecols=[5, 10, 12, 14])\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a165f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>docstring</th>\n",
       "      <th>code</th>\n",
       "      <th>short_docstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>iperf_time_compare\\nCompare two timestamps\\n\\n...</td>\n",
       "      <td>int\\niperf_time_compare(struct iperf_time *tim...</td>\n",
       "      <td>iperf_time_compare\\n Compare two timestamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>Search a table for an entry with matching valu...</td>\n",
       "      <td>static int npu_table_search(struct npu2 *p, ui...</td>\n",
       "      <td>Search a table for an entry with matching valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Conditionally reduce the per-virtual-corner ce...</td>\n",
       "      <td>static int cpr_reduce_ceiling_voltage(struct c...</td>\n",
       "      <td>Conditionally reduce the per-virtual-corner ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>The DMA API client is passing in a scatterlist...</td>\n",
       "      <td>int iommu_dma_map_sg(struct device *dev, struc...</td>\n",
       "      <td>The DMA API client is passing in a scatterlist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>Initialize a tunnel instance, handle pre and p...</td>\n",
       "      <td>void\\ninit_instance_handle_signals (struct con...</td>\n",
       "      <td>Initialize a tunnel instance, handle pre and p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                          docstring  \\\n",
       "0        C  iperf_time_compare\\nCompare two timestamps\\n\\n...   \n",
       "1        C  Search a table for an entry with matching valu...   \n",
       "2        C  Conditionally reduce the per-virtual-corner ce...   \n",
       "3        C  The DMA API client is passing in a scatterlist...   \n",
       "4        C  Initialize a tunnel instance, handle pre and p...   \n",
       "\n",
       "                                                code  \\\n",
       "0  int\\niperf_time_compare(struct iperf_time *tim...   \n",
       "1  static int npu_table_search(struct npu2 *p, ui...   \n",
       "2  static int cpr_reduce_ceiling_voltage(struct c...   \n",
       "3  int iommu_dma_map_sg(struct device *dev, struc...   \n",
       "4  void\\ninit_instance_handle_signals (struct con...   \n",
       "\n",
       "                                     short_docstring  \n",
       "0        iperf_time_compare\\n Compare two timestamps  \n",
       "1  Search a table for an entry with matching valu...  \n",
       "2  Conditionally reduce the per-virtual-corner ce...  \n",
       "3  The DMA API client is passing in a scatterlist...  \n",
       "4  Initialize a tunnel instance, handle pre and p...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09a2c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_sample = random.choices(dataset['test'], k=50)\n",
    "dataset_sample = []\n",
    "while len(dataset_sample) < 50:\n",
    "    message_string = random.choices(dataset['test'], k=1)\n",
    "    full_message = message_string[0]['func_documentation_string'] + message_string[0]['func_code_string']\n",
    "    if len(full_message) / 4 < 4000:\n",
    "        dataset_sample.append(message_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75727e7",
   "metadata": {},
   "source": [
    "# Testing the Baseline model\n",
    "\n",
    "Here we define the system prompt for the Llama 2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aa72c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_llama = \\\n",
    "'''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "You will be provided with a block of code and the existing doucmentation that accompanies it.\n",
    "Simplify the given documentation, using the provided code as context, so that it is understandable\n",
    "to beginner programmers. Output absolutely nothing else besides the simplified documentation.\n",
    "Make sure to keep any documentation formatting codes present in the simplified documentation.\n",
    "If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "it further, feel free to keep the documentation as is. Here is the original documentation and code:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd58925",
   "metadata": {},
   "source": [
    "Creating the pipeline for the Llama 2 model using the HuggingFace transformers library. Modified from the example here: https://huggingface.co/docs/transformers/en/model_doc/llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f17b609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b21a496a2b847a0a56c5bde12888d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8362a29d1ef94bd6a0823538fe742f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149b35de705a4772b34bc33376e1937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8cc25c497d4f1c942a0dea6bb6e5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f11754f54a4a6d9b630a342c67e4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5122a08cf555451985f9e64c860f7fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e6db50a99449a4aaf740cc8784120b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee53bb4420db44ee88e12051e2e43fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eaf07a5b4b4596ac99de0502a5121c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e502c582d4437b8b441efbe039e38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4aa4ca9acb0484db75535877ea92ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pipe_llama = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee38e16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1c7ff1fdca4bffa49c79510ffec04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1bea6f12984683bde62a7d118c3ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc48d146ced94c7d9d45b77a37bbeff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34dce419d2e4df5901d8dac5ac81793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a343490490540b687767285264695ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678fb60292a349fab1868b83ccfeaa68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f826b08422b14d3e955af367c81ca4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c25f0a0197414d97aa8c9b6e1e5d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d6b04be5864917b25b74b96edaed0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae9499a380a4c15a7953f51e3da2699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de2c9d121fe4ce48e6861074b561ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65530953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Documentation:\n",
      "Extracts video ID from URL.\n",
      "\n",
      "Code:\n",
      "def get_vid_from_url(url):\n",
      "        \"\"\"Extracts video ID from URL.\n",
      "        \"\"\"\n",
      "        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n",
      "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n",
      "          parse_query_param(url, 'v') or \\\n",
      "          parse_query_param(parse_query_param(url, 'u'), 'v')\n",
      "\n",
      "  Simplified Documentation:\n",
      "\n",
      "This function extracts the video ID from a URL. It uses a combination of regular expressions and query parameter parsing to extract the video ID from various parts of the URL.\n",
      "\n",
      "Here are the steps it follows:\n",
      "\n",
      "1. Checks if the URL contains the \"youtu.be\" domain and extracts the video ID from the URL using a regular expression.\n",
      "2. Checks if the URL contains the \"youtube.com/embed\" or \"youtube.com/v\" domains and extracts the video ID from the URL using regular expressions.\n",
      "3. Checks if the URL contains the \"youtube.com/watch\" domain and extracts the video ID from the URL using a regular expression.\n",
      "4. Parses the query parameters of the URL to extract the video ID.\n",
      "5. If the URL contains a \"u\" parameter, it parses the query parameters of the \"u\" parameter to extract the video ID.\n",
      "\n",
      "The function returns the extracted video ID as a string.\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    {\"role\": \"system\", \"content\": prompt_llama},\n",
    "    {\"role\": \"user\", \"content\": f\"Documentation:\\n{dataset['test'][0]['func_documentation_string']}\\n\\nCode:\\n{dataset['test'][0]['func_code_string']}\"}\n",
    "]\n",
    "print(f\"Original Documentation:\\n{dataset['test'][0]['func_documentation_string']}\\n\")\n",
    "print(f\"Code:\\n{dataset['test'][0]['func_code_string']}\\n\")\n",
    "print(pipe_llama(message, pad_token_id=pipe_llama.tokenizer.eos_token_id)[0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c386b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/adeniji/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56afffb4bf045ba86b01e46c455ad3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "llama_semantic_similarities_untrained = []\n",
    "llama_metrics_untrained = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "for instance in tqdm(dataset_sample):\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": prompt_llama},\n",
    "        {\"role\": \"user\", \"content\": f\"Documentation:\\n{instance[0]['func_documentation_string']}\\n\\nCode:\\n{instance[0]['func_code_string']}\"}\n",
    "    ]\n",
    "\n",
    "    result = pipe_llama(message, pad_token_id=pipe_llama.tokenizer.eos_token_id)[0]['generated_text'][-1]['content']\n",
    "\n",
    "    embedding_original = eval_model.encode(instance[0]['func_documentation_string'], convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    llama_semantic_similarities_untrained.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    llama_metrics_untrained.add(predictions=result, references=instance[0]['func_documentation_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f979a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n",
      "C#\n"
     ]
    }
   ],
   "source": [
    "for index, row in train_df.iterrows():\n",
    "    print(row['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1847f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prompt(language):\n",
    "    return \\\n",
    "    f'''You are a helpful agent designed to simplify code documentation for beginner programmers.\n",
    "    You will be provided with a block of {language} code and the existing doucmentation that accompanies it.\n",
    "    Simplify the given documentation, using the provided code as context, so that it is understandable\n",
    "    to beginner programmers. Output absolutely nothing else besides the simplified documentation.\n",
    "    Make sure to keep any documentation formatting codes present in the simplified documentation.\n",
    "    If you feel that the existing documentation is simple enough and meaning would be lost by simplifying\n",
    "    it further, feel free to keep the documentation as is. Here is the original documentation and code:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36182a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_semantic_similarities_untrained = []\n",
    "llama_metrics_untrained = evaluate.combine(['rouge', 'meteor'])\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    prompt_llama_training = return_prompt(row['language'])\n",
    "\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": prompt_llama},\n",
    "        {\"role\": \"user\", \"content\": f\"Documentation:\\n{row['docstring']}\\n\\nCode:\\n{row['code']}\"}\n",
    "    ]\n",
    "\n",
    "    result = pipe_llama(message, pad_token_id=pipe_llama.tokenizer.eos_token_id)[0]['generated_text'][-1]['content']\n",
    "\n",
    "    embedding_original = eval_model.encode(row['short_docstring'], convert_to_tensor=True)\n",
    "    embedding_predicted = eval_model.encode(result, convert_to_tensor=True)\n",
    "\n",
    "    llama_semantic_similarities_untrained.append(util.pytorch_cos_sim(embedding_original, embedding_predicted).item())\n",
    "    llama_metrics_untrained.add(predictions=result, references=row['short_docstring'])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80efc66",
   "metadata": {},
   "source": [
    "# Summary statistics results\n",
    "Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ad74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Untrained Llama 2: \\n\")\n",
    "pd.DataFrame(llama_semantic_similarities_untrained).describe()\n",
    "print(\"Trained Llama 2: \\n\")\n",
    "pd.DataFrame(llama_semantic_similarities_trained).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132c1db",
   "metadata": {},
   "source": [
    "ROUGE AND METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae45fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_metrics_untrained.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342d59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis732",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
